\documentclass[
    t,
    aspectratio=169,
    xcolor={
        svgnames,
        table,
        hyperref,
    },
    hyperref={
        pdfusetitle,    % Use PDF title
        pdfauthor={Sudip Sinha},    % Sets the document information Author field
        pdfsubject={doctoral defense},    % Sets the document information Subject field
        pdfkeywords={defense, dissertation, thesis, doctorate},    % Sets the document information Keywords field
        pdfstartview=Fit,    % Fits the page to the window
        pdfpagelayout=SinglePage,    % Displays a single page; advancing flips the page
        bookmarks=true,
        unicode=true,
        colorlinks=true,
        linktoc=all,
        hyperfootnotes=false,
        breaklinks=true,    % Correctly brake long URLs across lines
        linkcolor=Navy,
        urlcolor=IndianRed,
        citecolor=structure.fg,
    },
]{beamer}
\usetheme{Goettingen}

% Frame number
\setbeamertemplate{navigation symbols}{%
    \normalsize
    \insertframenumber
}

% Bullet style for itemize
\setbeamertemplate{itemize items}{>>}
\setbeamertemplate{itemize subitem}[ball]
\setbeamertemplate{itemize subsubitem}[square]

% Set fonts
% \setbeamerfont{frametitle}{size=\Large}
\setbeamerfont{framesubtitle}{size=\large}
\setbeamerfont{author}{size=\large}
\setbeamerfont{institute}{size=\normalsize}
\setbeamerfont{subsection in sidebar}{size=\tiny}

\usepackage{tikz}
\usetikzlibrary{decorations.markings}
% https://tex.stackexchange.com/questions/59926/how-to-draw-brownian-motions-in-tikz-pgf
\pgfmathsetseed{2}
\tikzset{help lines/.style={very thin,color=Linen}}
\newcommand{\BrownianPath}[5]{% points, advance, rand factor, options, end label
    \draw[#4] (0,0)
    \foreach \x in {1,...,#1} {
        -- ++(#2, rand * #3)
    }
    node[right] {#5};
}

\usepackage[english]{babel}	   % English hyphenation
\usepackage{csquotes}    % Multilingual quotes
\usepackage[
    protrusion=true,
    expansion=true,
    final,
    babel,
    nopatch=footnote,
]{microtype}    % Better typography
\usepackage{booktabs}


% Reference management
\usepackage[
    style=authoryear-icomp,
    sorting=nyt,
    backend=biber,
    maxnames=4,
]{biblatex}
\addbibresource{references/mypublications_presentation.bib}
\addbibresource{references/stochastics.bib}
\addbibresource{references/Wiener.bib}
\addbibresource{references/Kuo-integral.bib}
\addbibresource{references/Itô-integral.bib}
\addbibresource{references/large-deviations.bib}

% Math
\usepackage[
    math-style=ISO,
    bold-style=ISO,
    ]{unicode-math}

% Fonts
% \setmainfont{GFSArtemisia}
% \setmathfont{texgyrepagella-math.otf}

% XITS
% \setmainfont{XITS}
% \setmathfont{XITS Math}

% STIX2
\usefonttheme{serif}
\setmainfont{Stix Two Text}
\setmathfont{Stix Two Math}

\theoremstyle{definition}
\newtheorem{mytheorem}{Theorem}
\newcommand*{\heading}[1]{{\usebeamercolor[fg]{structure} #1}}

% Functions
\newcommand*{\floor}[1]{\ensuremath{\left\lfloor #1 \right\rfloor}}
\newcommand*{\ceil}[1]{\ensuremath{\left\lceil #1 \right\rceil}}
\newcommand*{\abs}[1]{\ensuremath{\left\lvert #1 \right\rvert}}
\newcommand*{\norm}[1]{\ensuremath{\left\lVert #1 \right\rVert}}
% Brackets
\newcommand*{\br}[1]{\ensuremath{\left( #1 \right)}}
\newcommand*{\bc}[1]{\ensuremath{\left\{ #1 \right\}}}
\newcommand*{\bs}[1]{\ensuremath{\left[ #1 \right]}}
\newcommand*{\ba}[1]{\ensuremath{\left\langle #1 \right\rangle}}
% Differentials
% \newcommand*{\dif}{\,\ensuremath{d}}
% \newcommand*{\Dif}{\ensuremath{D}}
% \newcommand*{\Del}{\ensuremath{Δ}}
\newcommand*{\dif}[1][]{\ensuremath{\operatorname{d}_{#1}\!}}
\newcommand*{\Dif}[1][]{\ensuremath{\operatorname{D}_{#1}\!}}
\newcommand*{\Del}[1][]{\ensuremath{\operatorname{Δ}_{#1}\!}}
% Miscellaneous
\renewcommand*{\Pr}{\ensuremath{ℙ\!}}
\newcommand*{\E}{\ensuremath{\operatorname{\mathbb{E}}\!}}
\newcommand*{\V}{\ensuremath{\operatorname{\mathbb{V}}\!}}
\newcommand*{\given}{\ensuremath{\; \middle| \;}}
\newcommand*{\inv}[1]{\ensuremath{{#1}^{-1}}}


% Beamer color commands
% \setbeamercolor{alerted text}{fg=Tomato}
\setbeamercolor{example text}{fg=structure.fg}
\newcommand{\good}[1]{\textcolor{ForestGreen}{#1}}
\newcommand{\bad}[1]{\textcolor{Tomato}{#1}}
\newcommand{\ad}[1]{\textcolor{Green}{#1}}
\newcommand{\ii}[1]{\textcolor{IndianRed}{#1}}
\newcommand{\sde}[1]{\textcolor{Orchid}{#1}}
\newcommand{\ode}[1]{\textcolor{DarkGoldenrod}{#1}}
\newcommand{\gen}[1]{\textcolor{DeepPink}{#1}}




\title[Doctoral Defense]{Anticipating Stochastic Integrals\\
and Related\\
Linear Stochastic Differential Equations}
\author{Sudip Sinha}
\institute[LSU]{Louisiana State University}
\date[2022-03-21]{March 21, 2022}


\begin{document}

\begin{frame}[plain]
    \titlepage
\end{frame}

\AtBeginSection[]{
    \begin{frame}{Outline}
        \tableofcontents[currentsection]
    \end{frame}
}

\AtBeginSubsection[]{
    \begin{frame}{Outline}
        \tableofcontents[currentsection,currentsubsection]
    \end{frame}
}

\begin{frame}{Main contributions}
    \begin{enumerate}
        \item  Extension of Itô's isometry
        \item  Near-martingale optional stopping theorem
        \item  LSDEs with anticipating initial conditions
        \begin{enumerate}
            \item  Solutions
            \item  Conditionals
        \end{enumerate}
        \item  LSDEs with anticipating coefficients
        \begin{enumerate}
            \item  Solutions in Ayed–Kuo theory
            \item  Solutions via a novel braiding technique
            \item  Large deviation principles
        \end{enumerate}
    \end{enumerate}
\end{frame}


\section{Background}

\begin{frame}{Wiener process / Brownian motion}
    \begin{tikzpicture}[domain=0:10]
        \draw[help lines] (0,-2.5) grid (9.5,2.5);

        \BrownianPath{1000}{0.01}{0.1}{PaleVioletRed}{\( W_⋅(ω_1) \)};
        \BrownianPath{1000}{0.01}{0.1}{DarkSlateBlue}{\( W_⋅(ω_2) \)};
        \BrownianPath{1000}{0.01}{0.1}{YellowGreen}{\( W_⋅(ω_3) \)};
        \BrownianPath{1000}{0.01}{0.1}{DarkSalmon}{\( W_⋅(ω_4) \)};
        \BrownianPath{1000}{0.01}{0.1}{Crimson}{\( W_⋅(ω_5) \)};
        \BrownianPath{1000}{0.01}{0.1}{Fuchsia}{\( W_⋅(ω_6) \)};
        \BrownianPath{1000}{0.01}{0.1}{Coral}{\( W_⋅(ω_7) \)};

        % t-axes
        \draw[->, very thick, color=gray] (0, 0) -- (11, 0) node[right] {\( t \)};
        % x-axis
        \draw[->, very thick, color=gray] (0, -3) -- (0, 3) node[right] {\( x \)};
        % t-axis markers
        \draw [ultra thick] (0 cm,1pt) -- (0 cm,-1pt) node[anchor=north east] {\( 0 \)};
        \draw [ultra thick] (10 cm,1pt) -- (10 cm,-1pt) node[anchor=north] {\( 1 \)};
    \end{tikzpicture}
\end{frame}

% \begin{frame}{Setup}
%     Assumptions:
%     \begin{itemize}
%         \item  \( t ∈ [0, 1] \) and \( \br{Ω, Σ, ℱ_⋅, \Pr} \) is a filtered space
%         \item  \( W_⋅ \) is a Wiener process on \( \br{Ω, Σ, ℱ_⋅, \Pr} \)
%     \end{itemize}

%     Properties of \( W \):
%     \begin{enumerate}
%         \item  Starts at 0
%         \item  Independent increments
%         \item  \( W_t - W_s ∼ 𝒩(0, \abs{t - s}) \)
%         \item  Continuous paths
%         \item  \bad{Unbounded linear variation}
%         \item  \good{Bounded quadratic variation}
%         \item  Martingale: \( \E\br{W_t \given ℱ_s} = W_s \) for any \( s ≤ t \)
%     \end{enumerate}

%     .
% \end{frame}

\begin{frame}{Stochastic integration}
    \heading{Setup}
    \begin{itemize}
        \item  \( t ∈ [0, 1] \) and \( \br{Ω, Σ, ℱ_⋅, \Pr} \) is a filtered space
        \item  \( W_⋅ \) is a Wiener process on \( \br{Ω, Σ, ℱ_⋅, \Pr} \)
        \item  A stochastic process \( \ad{X} \) is called \emph{\ad{adapted}} if \( X_t \) is \( ℱ_t \)-measurable \( ∀ t \)
    \end{itemize}

    \heading{Integration with respect to \( W \)}
    \begin{itemize}
        \item  Naive integration: not possible
        % \item  Utilize \good{bounded quadratic variation}
        \item  Wiener's integral: deterministic integrands
        \item  Itô's integral: \ad{adapted integrands}
    \end{itemize}

    \heading{Anticipating integrands}
    \begin{itemize}
        \item  Itô's idea of enlargement of filtration
        \item  Skorokhod integral and Malliavin calculus
        \item  White-noise distribution theory
        \item  \gen{Ayed–Kuo integral}
    \end{itemize}
\end{frame}

\begin{frame}{Itô's integral (\cite{Itô1944SI})}
    \heading{Basics}
    \begin{itemize}
        \item  \heading{Definition.} Let \( \Del W_i = W_{t_i} - W_{t_{i-1}} \). For \( X ∈ L^2_\text{\ad{ad}}\br{[0, 1] × Ω} \) as integrand: take \( L^2(Ω) \) limits of the \ad{left endpoint evaluation} of Riemann sums
        \[ \ad{M_t} ≜ ∫_0^t \ad{X_s} \dif W_s ≜ \lim_{n → ∞} ∑_{i = 1}^n \ad{X_{t_{i-1}}} \Del W_i  \quad \text{ in } L^2(Ω) . \]
        \item  \heading{Example.} \( ∫_0^t \ad{W_s} \dif W_s = \frac12 \br{W_t^2 - \alert{t}} \).
    \end{itemize}

    \heading{Properties}
    \begin{itemize}
        \item  Linearity
        \item  Mean: \( 0 \)
        \item  Variance: \( \norm{\ad{M}}_{L^2(Ω)} = \norm{\ad{X}}_{L^2_\text{\ad{ad}}\br{[0, t] × Ω}} \) (\alert{Itô's isometry})
        \item  Martingale: \( \E\br{\ad{M_t} \given ℱ_s} = \ad{M_s} \) for any \( s ≤ t \)
    \end{itemize}
\end{frame}

% \begin{frame}{Itô's lemma}
%     Itô processes:
%     \begin{itemize}
%         \item  Processes of the form \( \ad{X_⋅} = \ad{X_0} + ∫_0^⋅ \ad{m_t} \dif t + ∫_0^⋅ \ad{σ_t} \dif W_t \), where \( \ad{m} ∈ L^1_\text{\ad{ad}}\br{[0, t] × Ω} \) and \( \ad{σ} ∈ L^2_\text{\ad{ad}}\br{[0, t] × Ω} \).
%         \item  We write \( \dif \ad{\ad{X_t}} =  \ad{m_t} \dif t + \ad{σ_t} \dif W_t \).
%     \end{itemize}

%     \begin{mytheorem}[\cite{Itô1944SI}]
%         Suppose \( θ(t, x_1, \dotsc, x_n) \) is \( C^1 \) in \( t \) and \( C^2 \) in the others. Then for Itô processes \( \br{ \ad{X^{(i)}_⋅} }_{i = 1}^n \),
%         \begin{equation*}
%             \dif θ\br{ t, \ad{X^{(1)}_t}, \dotsc, \ad{X^{(n)}_t} }
%             = θ_t \dif t
%             +  ∑_{i = 1}^n θ_{x_i} \dif \ad{X^{(i)}_t}
%             +  \frac12 ∑_{i, j = 1}^n θ_{x_i x_j} \dif \ad{X^{(i)}_t} \dif \ad{X^{(j)}_t} ,
%         \end{equation*}
%         where \( \dif \ad{X^{(i)}_t} \dif \ad{X^{(j)}_t} \) is evaluated using the rule that \( \br{\dif W^{(i)}_t}^2 = \dif t \) for any \( i ∈ \bc{1, 2, \dotsc, n} \), any other product being zero.
%     \end{mytheorem}
% \end{frame}

\begin{frame}{Linear stochastic differential equations (LSDEs)}
    \begin{itemize}
        \item  Linear differential equations incorporating \textquote{noise}, for example
        \[ \frac{\dif \ad{X_t}}{\dif t} = \ad{β_t} ~ \ad{X_t} + \ad{α_t} ~ \ad{X_t} ~ \alert{\dot{W}_t} . \]

        \item  \alert{But \( \dot{W}_t \) is meaningless.} Heuristically, we multiply by \( \dif t \), write \( \dot{W}_t \dif t = \dif W_t \), and interpret the second expression as an Itô integral.

        \item  \heading{Example.} For adapted \( \ad{α} \) and \( \ad{β} \), the following is an LSDE
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \ad{X_t}  & =  \ad{α_t} ~ \ad{X_t} \dif W_t + \ad{β_t} ~ \ad{X_t} \dif t , \\
                \ad{X_0}  & =  1 .
            \end{aligned}
            \right.
        \end{equation*}

        \item  The solution is given by the \emph{exponential process}
        \[ \ad{ℰ_t} = \exp\br{∫_0^t \ad{α_s} \dif W_s + ∫_0^t \br{\ad{β_s} - \frac12 \ad{α_s^2}} \dif s} . \]
    \end{itemize}
\end{frame}




\section{The Ayed–Kuo integral}

\subsection{Essential ideas}

\begin{frame}{Idea}
    \begin{itemize}
        \item  A stochastic process \( \ii{Y} \) is called \emph{\ii{instantly-independent}} (\ii{i.i.}) if \( Y^t \) and \( ℱ_t \) are independent \( ∀ t \).
        \item  Decompose the integrand into \ad{adapted} and \ii{i.i.} components.
        \item  \ad{Left} endpoint evaluation for \ad{adapted} processes.
        \item  \ii{Right} endpoint evaluation for \ii{i.i.} processes.
    \end{itemize}

    \begin{figure}
        \centering
        \begin{tikzpicture}
            % Adapted
            \fill [Green!12] (0,0) rectangle (3,1.5);
            \node (ad) at (1.5, 1.75) [Green] {\( ℱ_s \)};

            % Instantly-independent
            \fill [IndianRed!12] (3,0) rectangle (8,1.5);
            \node (ii) at (5.5, 1.75) [IndianRed] {\( 𝒢^s \)};

            % Main timeline
            \draw [->, very thick, color=gray] (-1,0) -- (9,0) node[below] {\( t \)};
            \foreach \x/\xtext in {0/0, 3/s, 8/1}
                \draw [ultra thick] (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\xtext$};

            % Adapted
            % W_t
            \draw [very thick, color=Green] (0,0.5) -- (3,0.5);
            \draw [color=Green] (1.5,0.8) node {\( \br{W_u}_{u ∈ [0, s]} \)};
            \draw [fill=Green] (0,0.5) circle (1.5pt);
            \draw [fill=Green] (3,0.5) circle (1.5pt);

            % ϕ_j
            \draw [very thick, color=IndianRed] (3,1) -- (8,1);
            \draw [color=IndianRed] (5.5,0.65) node {\( \br{W_1 - W_u}_{u ∈ [s, 1]} \)};
            \draw [fill=IndianRed] (3,1) circle (1.5pt);
            \draw [fill=IndianRed] (8,1) circle (1.5pt);

            % Setup and bounding box
            % \clip(-2,-1) rectangle (9,3);
            % \draw (current bounding box.north east) rectangle (current bounding box.south west);
        \end{tikzpicture}
    \end{figure}
\end{frame}

\begin{frame}{Example}{\cite[equation 1.6]{AyedKuo2008}}
    \begin{align*}
        \gen{N(t)}
        =  ∫_0^t \gen{W_1} \dif W_s
        & =  ∫_0^t \bs{\ad{W_s} + \br{\ii{W_1- W_s}}} \dif W_s  \\
        & =  \lim_{n → ∞} ∑_{i = 1}^n \bs{ \ad{W_{t_{i-1}}} + \br{\ii{W_1 - W_{t_i}}} } \Del W_i \\
        & =  \lim_{n → ∞} ∑_{i = 1}^n \br{\gen{W_1} - \Del W_i} \Del W_i  \\
        & =  \gen{W_1} ⋅ \lim_{n → ∞} ∑_{i = 1}^n \Del W_i - \lim_{n → ∞} ∑_{i = 1}^n (\Del W_i)^2  \\
        & =  \gen{W_1} W_t - t .
    \end{align*}
\end{frame}

\begin{frame}{Definition (\cite{AyedKuo2008})}
    \begin{itemize}
        \item  For \ad{\( X \) adapted} and \ii{\( Y \) instantly-independent}, define
        \begin{equation*}
            ∫_0^1 \ad{\ad{X_t}} ~ \ii{Y^t} \dif W_t = \lim_{m → ∞} ∑_{j = 1}^m \ad{X_{t_{j - 1}}} \ii{Y^{t_j}} \Del W_i  \quad \text{ in } L^2(Ω).
        \end{equation*}
        Extend to linear combinations.

        \item  Let \( \gen{Z} \) be a stochastic process such that a sequence \( \br{\gen{Z_n}}_{n = 1}^∞ \) of stochastic processes each of the form above (or linear combinations thereof) satisfies
        \begin{enumerate}
            \item  \( ∫_0^1 \abs{\gen{Z_n(t)} - \gen{Z(t)}}^2 \dif t → 0 \) as \( n → ∞ \) almost surely, and
            \item  \( ∫_0^1 \gen{Z_n(t)} \dif W_t \) converges in \( L^2(Ω) \) as \( n → ∞ \).
        \end{enumerate}
        Then the stochastic integral of \( \gen{Z} \) is defined by the following (if it exists):
        \begin{equation*}
            ∫_0^1 \gen{Z(t)} \dif W_t = \lim_{n → ∞}  ∫_0^1 \gen{Z_n(t)} \dif W_t  \quad \text{ in } L^2(Ω) .
        \end{equation*}

        % \item  Well-defined (\cite[lemma 2.1]{HwangKuoSaitôZhai2016}).
    \end{itemize}
\end{frame}

\begin{frame}{Differential formula}{\cite[theorem 3.2]{HwangKuoSaitôZhai2016}}
    \begin{table}[ht]
        \begin{tabular}{cll}
            \toprule
            type  &  definition  &  representation  \\
            \midrule
            Itô   &  \( \ad{X_⋅} = \ad{X_0} + ∫_0^⋅ \ad{m_t} \dif t + ∫_0^⋅ \ad{σ_t} \dif W_t \)  &  \( \dif \ad{\ad{X_t}} =  \ad{m_t} \dif t + \ad{σ_t} \dif W_t \)  \\
            i.i.  &  \( \ii{Y^⋅} = \ii{Y^1} + ∫_⋅^1 \ii{η_t} \dif t + ∫_⋅^1 \ii{ζ_t} \dif W_t \)  &  \( \dif \ii{Y^t} = -\ii{η_t} \dif t - \ii{ζ_t} \dif W_t \)  \\
            \bottomrule
        \end{tabular}
    \end{table}
    Here \( \ii{η_t} \) and \( \ii{ζ_t} \) are i.i. such that \( \ii{Y} \) is also i.i.

    Assume \( θ(t, \ad{x}, \ii{y}) ∈ C^{1, \ad{2}, \ii{2}}([0, 1] × \ad{ℝ} × \ii{ℝ}) \). Then
    \begin{align*}
        \dif θ\br{ t, \ad{X_t}, \ii{Y^t} }
        =  θ_t \dif t
        &  +  θ_x \dif \ad{X_t}
        +  \frac12 θ_{x x} \br{\dif \ad{X_t}}^2  \\
        &  +  θ_y \dif \ii{Y^t}
        \alert{-}  \frac12 θ_{y y} \br{\dif \ii{Y^t}}^2 ,
    \end{align*}
    where \( \br{\dif W_t}^2 = \dif t \), all other products being zero.
\end{frame}



\subsection{Extension of Itô's isometry}

\begin{frame}{Identity for a simple case}
    \begin{mytheorem}[{\cite[theorem 3.1]{KuoShresthaSinha2021isometry}}]
        Suppose \( f, ϕ ∈ C^1(ℝ) \) such that
        \[ f(\ad{W_t}) ~ ϕ(\ii{W_1 - W_t}), ~ f(\ad{W_t}) ~ ϕ'(\ii{W_1 - W_t}), ~ f'(\ad{W_t}) ~ ϕ(\ii{W_1 - W_t}) ∈ L^2([0, 1] × Ω) . \]
        Then \( \E\bs{ ∫_0^1 f(\ad{W_t}) ~ ϕ(\ii{W_1 - W_t}) \dif W_t } = 0 \), and
        \begin{align*}
            &  \E\bs{ \br{∫_0^1 f(\ad{W_t}) ~ ϕ(\ii{W_1 - W_t}) \dif W_t}^2}  =  ∫_0^1 \E\bs{ f(\ad{W_t})^2 ~ ϕ(\ii{W_1 - W_t})^2 } \dif t  \\
            &  \qquad \qquad +  2 ∫_0^1 ∫_0^t \E\bs{ f(\ad{W_s}) ~ ϕ'(\ii{W_1 - W_s}) ~ f'(\ad{W_t}) ~ ϕ(\ii{W_1 - W_t}) } \dif s \dif t .
        \end{align*}
    \end{mytheorem}

    \pause

    \heading{Remark.} The double integral term can take any real value (\cite[example 3.9]{KuoShresthaSinha2021isometry}).
\end{frame}

\begin{frame}{Proof idea}
    \begin{itemize}
        \item<1->  Write integral as \( L^2(Ω) \)-limit of sums over partitions of \( [0, 1] \).
        \item<1->  Diagonal: Use quadratic variation of \( W \).
        \item<2->  Off-diagonal: Use the expectation and approximation identities.
        \begin{itemize}
            \item  \temporal<4-5>{\( \E\bs{ f\br{\ad{W_{t_{i-1}}}} ~ ϕ\br{\ii{W_b - W_{t_i}} - \alert{\Del W_j}} ~ f\br{\ad{W_{t_{j-1}}}} ~ ϕ\br{\ii{W_1 - W_{t_j}}} \Del W_i \Del W_j} = 0 \)}{\( \E\bs{ f\br{\ad{W_{t_{i-1}}}} ~ ϕ\br{\ii{W_b - W_{t_i}}} ~ f\br{\ad{W_{t_{j-1}}} - \alert{\Del W_i}} ~ ϕ\br{\ii{W_1 - W_{t_j}}} \Del W_i \Del W_j} = 0 \)}{Zero expectation}.
            \item  \temporal<4-5>{\( ϕ\br{\ii{W_b - W_{t_i}}} - ϕ\br{\ii{W_b - W_{t_i}} - \alert{\Del W_j}} ≃ ϕ'\br{\ii{W_b - W_{t_i}} - \Del W_j} \Del W_j \)}{\( f\br{\ad{W_{t_{j-1}}}} - f\br{\ad{W_{t_{j-1}}} - \alert{\Del W_i}} ≃ f'\br{\ad{W_{t_{j-1}}} - \Del W_i} \Del W_i \)}{Approximation}.
            \item  \temporal<4-5>{Conditioning w.r.t. \( ℋ_{t_{j-1}}^{t_j} \), noting \( \Del W_j \) is independent of \( ℋ_{t_{j-1}}^{t_j} \)}{Conditioning w.r.t. \( ℋ_{t_{i-1}}^{t_i} \), noting \( \Del W_i \) is independent of \( ℋ_{t_{i-1}}^{t_i} \)}{Conditioning w.r.t. the \alert{separation σ-algebra}}.
        \end{itemize}
    \end{itemize}

    \begin{figure}
        \centering
        \begin{tikzpicture}
            % ℋ_{t_{j-1}}^{t_j}
            \onslide<2-3>{\fill [RosyBrown!25] (0,0) rectangle (5,2.125);}
            \onslide<2-3>{\fill [RosyBrown!25] (6,0) rectangle (8,2.125);}
            \onslide<2-3>{\node (separation) at (5.5, 2.5) [RosyBrown] {\( ℋ_{t_{j-1}}^{t_j} \)};}
            \onslide<2-3>{\draw [->, thick, color=RosyBrown] (separation.west) to [bend right=10] (2.5,2);}
            \onslide<2-3>{\draw [->, thick, color=RosyBrown] (separation.east) to [bend left=10 ] (7.0,2);}

            % ℋ_{t_{i-1}}^{t_i}
            \onslide<4->{\fill [RosyBrown!25] (0,0) rectangle (2,2.125);}
            \onslide<4->{\fill [RosyBrown!25] (3,0) rectangle (8,2.125);}
            \onslide<4->{\node (separation) at (2.5, 2.5) [RosyBrown] {\( ℋ_{t_{i-1}}^{t_i} \)};}
            \onslide<4->{\draw [->, thick, color=RosyBrown] (separation.west) to [bend right=10] (1.0,2);}
            \onslide<4->{\draw [->, thick, color=RosyBrown] (separation.east) to [bend left=10 ] (5.5,2);}

            % Main timeline
            \draw [->, very thick, color=gray] (-1,0) -- (9,0) node[below] {\( t \)};
            \foreach \x/\xtext in {0/0, 2/t_{i-1}, 3/t_i, 5/t_{j-1}, 6/t_j, 8/1}
                \draw [ultra thick] (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\xtext$};

            % Adapted
            % f_{i-1}
            \draw [color=Green] (1,1) node {\( f_{i-1} \)};
            \draw [very thick, color=Green] (0,0.75) -- (2,0.75);
            \draw [fill=Green] (0,0.75) circle (1.5pt);
            \draw [fill=Green] (2,0.75) circle (1.5pt);

            % f_{j-1}
            \draw [color=Green] (2.5,1.75) node {\( f_{j-1} \)};
            \onslide<1-4>{\draw [very thick, color=Green] (0,1.5) -- (5,1.5);}
            \onslide<5->{\draw [very thick, color=Green] (0,1.5) -- (2,1.5);}
            \onslide<5->{\draw [very thick, densely dotted, color=Green] (2,1.5) -- (3,1.5);}
            \onslide<5->{\draw [very thick, color=Green] (3,1.5) -- (5,1.5);}
            \draw [fill=Green] (0,1.5) circle (1.5pt);
            \draw [fill=Green] (5,1.5) circle (1.5pt);

            % Instantly independent
            % ϕ_i
            \draw [color=IndianRed] (5.5,1) node {\( ϕ_{i} \)};
            \onslide<1-2>{\draw [very thick, color=IndianRed] (3,0.75) -- (8,0.75);}
            \onslide<3->{\draw [very thick, color=IndianRed] (3,0.75) -- (5,0.75);}
            \onslide<3->{\draw [very thick, densely dotted, color=IndianRed] (5,0.75) -- (6,0.75);}
            \onslide<3->{\draw [very thick, color=IndianRed] (6,0.75) -- (8,0.75);}
            \draw [fill=IndianRed] (3,0.75) circle (1.5pt);
            \draw [fill=IndianRed] (8,0.75) circle (1.5pt);

            % ϕ_j
            \draw [color=IndianRed] (7,1.75) node {\( ϕ_{j} \)};
            \draw [very thick, color=IndianRed] (6,1.5) -- (8,1.5);
            \draw [fill=IndianRed] (6,1.5) circle (1.5pt);
            \draw [fill=IndianRed] (8,1.5) circle (1.5pt);

            % Setup and bounding box
            % \clip(-2,-1) rectangle (9,3);
            % \draw (current bounding box.north east) rectangle (current bounding box.south west);
        \end{tikzpicture}
    \end{figure}
\end{frame}

\begin{frame}{Discussion}
    \begin{itemize}
        \item  Shown before under restrictive conditions (\cite[theorem 3.1]{KuoSaeTangSzozda2013}).
        \item  Vast improvement over the previous result.
        \item  Minimal restrictions on \( f \) and \( ϕ \).
        \item  Short, direct, probabilistic proof.
        \item  Utilize the \ad{left} and \ii{right} evaluation point definition of the integral.
        \item  Introduce the \alert{separation σ-algebra} as the canonical σ-algebra to condition on for the Ayed–Kuo integral.
    \end{itemize}
\end{frame}

\begin{frame}{General form (\cite[theorem 3.6]{KuoShresthaSinha2021isometry})}
    Let \( Θ(x, y), ~ Λ(x, y) ∈ C^1(ℝ^2) \) and assume that
    \begin{enumerate}
        \item  \( Θ(\ad{W_t}, \ii{W_1 - W_t}), ~ Θ_x(\ad{W_t}, \ii{W_1 - W_t}), ~ Θ_y(\ad{W_t}, \ii{W_1 - W_t}) ∈ L^2([0, 1] × Ω) \), and
        \item  \( Λ(\ad{W_t}, \ii{W_1 - W_t}), ~ Λ_x(\ad{W_t}, \ii{W_1 - W_t}), ~ Λ_y(\ad{W_t}, \ii{W_1 - W_t}) ∈ L^2([0, 1] × Ω) \).
    \end{enumerate}
    Then
    \begin{align*}
        &  \E\bs{ \br{∫_0^1 Θ(\ad{W_t}, \ii{W_1 - W_t}) \dif W_t} \br{∫_0^1 Λ(\ad{W_t}, \ii{W_1 - W_t}) \dif W_t}}  \\
        &  =  ∫_0^1 \E\bs{ Θ(\ad{W_t}, \ii{W_1 - W_t}) ~ Λ(\ad{W_t}, \ii{W_1 - W_t})} \dif t  \\
        &  \quad  +  ∫_0^1 ∫_0^t \E \Big[
            Θ_y(\ad{W_s}, \ii{W_1 - W_s}) ~ Λ_x(\ad{W_t}, \ii{W_1 - W_t})  \\
        &   \qquad \qquad \qquad  + Θ_x(\ad{W_t}, \ii{W_1 - W_t}) ~ Λ_y(\ad{W_t}, \ii{W_1 - W_t})
        \Big] \dif s \dif t .
    \end{align*}
\end{frame}



\subsection{Near-martingales}

\begin{frame}{Setup}
    \heading{Motivation}
    \begin{itemize}
        \item  Process defined by Itô integrals \( \ad{M_t} = ∫_0^t \ad{X_s} \dif W_s \) are martingales.

        \item  Are Ayed–Kuo integrals martingales?

        \item  \heading{Example.} \( \gen{N(t)} =  ∫_0^t \gen{W_1} \dif W_s = W_1 W_t - t \).

            Now, \( \E\br{\gen{N(t)} \given ℱ_s}  =  W_s^2 - s  ≠  W_1 W_s - s  =  \gen{N(s)} \), so \alert{not a martingale}.

            However, \( \E\br{\gen{N(s)} \given ℱ_s} = W_s^2 - s = \E\br{\gen{N(t)} \given ℱ_s} \).
    \end{itemize}

    \pause

    \begin{definition}[{\cite[definition 2.1]{HwangKuoSaitôZhai2017}}]
        An integrable stochastic process \( \gen{N} \) is called a \emph{near-martingale} if \( \E\br{\gen{N(t)} - \gen{N(s)} \given ℱ_s} = 0 \) almost surely for every \( s ≤ t \).
    \end{definition}

    \pause

    \begin{mytheorem}[{\cite[theorem 2.5]{HwangKuoSaitôZhai2017}}]
        A process \( \gen{N} \) is a near-martingale if and only if the conditioned process \( \ad{M} \) given by \( \ad{M_t} = \E\br{\gen{N(t)} \given ℱ_t} \) is a martingale.
    \end{mytheorem}
\end{frame}

\begin{frame}{Optional stopping theorem}
    \begin{mytheorem}[{\cite[theorem 3.3]{KuoShresthaSinhaSundar2022}}]
        Suppose \( Θ: ℝ^2 → ℝ \) is measurable. Then the processes
        \[ \gen{N(t)} = ∫_0^t Θ(\ad{W_u}, \ii{W_1 - W_u}) \dif W_u  \quad \text{and} \quad  \gen{\widetilde{N}(t)} = ∫_t^1 Θ(\ad{W_u}, \ii{W_1 - W_u}) \dif W_u \]
        are near-martingales.
    \end{mytheorem}

    \begin{mytheorem}[{\cite[theorem 3.10]{KuoShresthaSinhaSundar2022}}]  \label{thm:optional_stopping_near-martingale_continuous}
        Let \( \gen{N} \) be a near-submartingale with right-continuous sample paths. Suppose \( σ ≤ τ \) are two bounded stopping. If \( N \) is either non-negative or uniformly integrable, then \( \gen{N(σ)} \) and \( \gen{N(τ)} \) are integrable, and \[ \E\br{\gen{N(τ)} - \gen{N(σ)} \given ℱ_σ} ≥ 0  \text{ almost surely.} \]
    \end{mytheorem}
\end{frame}




\section{LSDEs with anticipating initial conditions}

\subsection{Solutions}

\begin{frame}{Motivation}
    \begin{block}{}
        For \( x ∈ ℝ \), the solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \ad{X_t}  & =  \ad{X_t} \dif W_t  \\
                    \ad{X_0}  & =  x
            \end{aligned}
            \right.
        \end{equation*}
        is \( \ad{X_t} = x \exp\br{W_t - \frac12 t} \).
    \end{block}

    \pause

    \begin{block}{}
        However, the solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  \gen{Z(t)} \dif W_t  \\
                    \gen{Z(0)}  & =  \gen{W_1}
            \end{aligned}
            \right.
        \end{equation*}
        is \alert{not} \( \gen{Z(t)} = \gen{W_1} \exp\br{W_t - \frac12 t} \).
    \end{block}
\end{frame}

\begin{frame}{Non-intuitive nature}
    \onslide<1-3>
    \begin{example}[{\cite[section 3]{KhalifaKuoOuerdianeSzozda2013}}]
        The solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  \gen{Z(t)} \dif W_t  \\
                     \gen{Z(0)}  & =  \gen{W_1}
            \end{aligned}
            \right.
        \end{equation*}
        is given by \( \gen{Z(t)} = (\gen{W_1} - \alert{t}) \exp\br{W_t - \frac12 t} \).
    \end{example}

    \pause

    \onslide<2>
    \begin{example}[{\cite[example 4.1]{AyedKuo2008}}]
        The solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  \gen{Z(t)} \dif W_t  +  \alert{\frac{1}{W_1} Z(t) \dif t}  \\
                     \gen{Z(0)}  & =  1
            \end{aligned}
            \right.
        \end{equation*}
        is given by \( \gen{Z(t)} = \gen{W_1} \exp\br{W_t - \frac12 t} \).
    \end{example}

    % \begin{example}[{\cite[example 4.2]{AyedKuo2008}}]
    %     The solution of
    %     \begin{equation*}
    %         \left\{
    %         \begin{aligned}
    %             \dif \ad{X_t}  & =  \ad{X_t} \dif W_t + \frac{1}{x} \ad{X_t} \dif t  \\
    %                  \ad{X_0}  & =  x
    %         \end{aligned}
    %         \right.
    %     \end{equation*}
    %     is given by \( \ad{X_t} = x \exp\br{W_t - \frac12 t + \frac{1}{x} t} \).
    % \end{example}
\end{frame}

\begin{frame}{Generalization}
    \begin{mytheorem}[{\cite[theorem 5.1]{KuoSinhaZhai2018}}]
        Let \( α, h ∈ L^2[0, 1] \), \( β ∈ L^1[0, 1] \) and \( ϕ ∈ C^2(ℝ) \). Then the solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  α(t) ~ \gen{Z(t)} \dif W_t + β(t) ~ \gen{Z(t)} \dif t ,  &  t ∈ [0, 1]  \\
                     \gen{Z(0)}  & =  ϕ\Big( \gen{∫_0^1 h(s) \dif W_s} \Big) ,
            \end{aligned}
            \right.
        \end{equation*}
        is given by
        \[ \gen{Z(t)} = ϕ\Big( \gen{∫_0^1 h(s) \dif W_s} - \alert{∫_0^t α(s) ~ h(s) \dif s} \Big) ~ \ad{ℰ_t} . \]
    \end{mytheorem}

    \pause

    \heading{Proof idea.} \alert{Use an ansatz} and then apply the differential formula.
\end{frame}

\begin{frame}{Further generalization}
    \begin{mytheorem}[{\cite[theorem 4.2]{KuoShresthaSinha2021conditional}}]
        Let \( \ad{α} ∈ L^2_\text{\ad{ad}}([0, 1] × Ω) \), \( \ad{β} ∈ L^1_\text{\ad{ad}}([0, 1] × Ω) \) be stochastic processes. Suppose \( h ∈ L^2[0, 1] \) and \( ϕ ∈ C^2(ℝ) \) are deterministic functions. Then the solution of
        \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \gen{Z(t)}  & =  \ad{α_t} ~ \gen{Z(t)} \dif W_t + \ad{β_t} ~ \gen{Z(t)} \dif t ,  \\
                 \gen{Z(0)} & =  ϕ\Big( \gen{∫_0^1 h(s) \dif W_s} \Big) ,
        \end{aligned}
        \right.
        \end{equation*}
        is given by
        \begin{equation*}
            \gen{Z(t)} = ϕ\Big( \gen{∫_0^1 h(s) \dif W_s} - \alert{∫_0^t h(s) ~ α_s \dif s} \Big) ~ \ad{ℰ_t} .
        \end{equation*}
    \end{mytheorem}

    \heading{Proof idea.} \alert{Use an ansatz} and then apply the differential formula.
\end{frame}



\subsection{Conditionals}

\begin{frame}{Motivation and setup}
    For \( \ad{α} ∈ L^2_\text{\ad{ad}}([0, 1] × Ω) \), \( \ad{β} ∈ L^1_\text{\ad{ad}}([0, 1] × Ω) \), and \( h ∈ L^2[0, 1] \), consider
    \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \gen{Z(t)}  & =  \ad{α_t} ~ \gen{Z(t)} \dif W_t + \ad{β_t} ~ \gen{Z(t)} \dif t  \\
            \gen{Z(0)}  & =  ϕ \Big( \gen{∫_0^1 h(s) \dif W_s} \Big) ,
        \end{aligned}
        \right.
    \end{equation*}
    and the conditioned process
    \[ \ad{X_t} = \E\br{\gen{Z(t)} \given ℱ_t} . \]

    \heading{Questions}
    \begin{itemize}
        \item  What SDE does \( \ad{X} \) satisfy?
        \item  What is the relationship between the SDEs of \( \ad{X} \) and \( \gen{Z} \)?
        \item  Is there a formula to obtain \( \ad{X} \) from \( \gen{Z} \) directly?
    \end{itemize}
\end{frame}

\begin{frame}{Analytic functions (\cite[theorem 5.1]{KuoShresthaSinha2021conditional})}
    Let \( ϕ \) is an analytic function on \( ℝ \) with derivative \( ϕ' \). Furthermore, let \( \gen{Z(t)} \) be the solution of
    \begin{equation*}
        \dif \gen{Z(t)}  =  \ad{α_t} ~ \gen{Z(t)} \dif W_t + \ad{β_t} ~ \gen{Z(t)} \dif t ,
        \quad  \gen{Z(0)}  =  ϕ \Big( \gen{∫_0^1 h(s) \dif W_s} \Big) ,
    \end{equation*}
    and \( \ad{X_t} = \E\br{\gen{Z(t)} \given ℱ_t} \) is the conditioned process. Then \( \ad{X} \) satisfies
    \begin{equation*}
        \dif \ad{X_t}  =  \ad{α_t} ~ \ad{X_t} \dif W_t + \ad{β_t} ~ \ad{X_t} \dif t + \alert{h(t) ~ \widetilde{X}_t \dif W_t} ,
        \quad  \ad{X_0}  =  \E\bigg[ϕ \Big( \gen{∫_0^1 h(s) \dif W_s} \Big)\bigg] ,
    \end{equation*}
    where \( \ad{\widetilde{X}_t} = \E\br{\gen{\widetilde{Z}(t)} \given ℱ_t} \), and \( \gen{\widetilde{Z}} \) is the solution of
    \begin{equation*}
        \dif \gen{\widetilde{Z}(t)}  =  \ad{α_t} ~ \gen{\widetilde{Z}(t)} \dif W_t + \ad{β_t} ~ \gen{\widetilde{Z}(t)} \dif t ,
        \quad  \gen{\widetilde{Z}(0)}  =  ϕ' \Big( \gen{∫_0^1 h(s) \dif W_s} \Big) .
    \end{equation*}
\end{frame}

\begin{frame}{Special case: the exponential function}
    \begin{example}[{\cite[example 5.3]{KuoShresthaSinha2021conditional}}]
        The solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \ad{X_t}  & =  (\ad{α_t} + h(t)) ~ \ad{X_t} \dif W_t + \ad{β_t} ~ \ad{X_t} \dif t,  \\
                     \ad{X_0}  & =  1.
            \end{aligned}
            \right.
        \end{equation*}
        is given by
        \begin{equation*}
            \ad{X_t} = \ad{ℰ_t} \exp\Big( ∫_0^t h(s) \dif W_s - ∫_0^t h(s) ~ \ad{α_s} \dif s \Big) .
        \end{equation*}
    \end{example}
\end{frame}

\begin{frame}{Hermite polynomials}{\cite[theorem 5.5]{KuoShresthaSinha2021conditional}}
    For a fixed \( n ∈ ℕ \), suppose \( Z \) is the solution of
    \begin{equation*}
        \dif \gen{Z(t)}  =  \ad{α_t} \gen{Z(t)} \dif W_t + \ad{β_t} \gen{Z(t)} \dif t ,  \quad  \gen{Z(0)}  =  H_n \Big( \gen{∫_0^1 h(s) \dif W_s} ~; ∫_0^1 h(s)^2 \dif s \Big) .
    \end{equation*}
    Then \( \ad{X_t} = \E\br{\gen{Z(t)} \given ℱ_t} \) is given by
    \begin{equation*}
        \ad{X_t} = H_n \Big( ∫_0^t h(s) \dif W_s - \alert{∫_0^t h(s) ~ α_s \dif s} ~; ∫_0^t h(s)^2 \dif s \Big) ~ \ad{ℰ_t} .
    \end{equation*}
    Moreover, \( \ad{X_t} \) satisfies
    \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \ad{X_t}  & =  \ad{α_t} \ad{X_t} \dif W_t + \ad{β_t} \ad{X_t} \dif t  \\
                &  \quad  + \alert{ n H_{n-1} \Big( ∫_0^t h(s) \dif W_s - ∫_0^t h(s) ~ α_s \dif s ~; ∫_0^t h(s)^2 \dif s \Big) ~ ℰ_t ~ h(t) \dif W_t } \\
            \ad{X_0}  & =  0 .
        \end{aligned}
        \right.
    \end{equation*}
\end{frame}




\section{LSDEs with anticipating coefficients}

\subsection{Solutions via ansatz}

\begin{frame}{Motivation}
    \begin{itemize}
        \item  In Itô's theory, for an adapted process \( \ad{H_t} \), the solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \ad{X_t}  & =  \ad{H_t} ~ \ad{X_t} \dif W_t  \\
                \quad \ad{X_0}  & =  1
            \end{aligned}
            \right.
        \end{equation*}
        is given by
        \begin{equation*}
            \ad{X_t}
            =  \exp\br{∫_0^t \ad{H_s} \dif W_s - \frac12 ∫_0^t \ad{H_s^2} \dif s} .
        \end{equation*}

        \pause

        \item  On the other hand, the solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  \gen{W_1} ~ \gen{Z(t)} \dif W_t  \\
                     \gen{Z(0)}  & =  1
            \end{aligned}
            \right.
        \end{equation*}
        for the anticipating coefficient \( \gen{W_1} \) is \alert{not} given by
        \begin{equation*}
            \gen{Z(t)}
            =  \exp\br{∫_0^t \gen{W_1} \dif W_s - \frac12 ∫_0^t \gen{W_1^2} \dif s}
            =  \exp\br{\gen{W_1} ~ \alert{W_t} - t - \alert{\frac12 t} \gen{W_1^2}} .
        \end{equation*}
    \end{itemize}
\end{frame}

\begin{frame}{Non-trivial nature}
    \onslide<1-3>
    \begin{example}[{\cite[theorem 3.1]{HwangKuoSaitô2019}}]
        The solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  \gen{W_1} ~ \gen{Z(t)} \dif W_t  \\
                \gen{Z(0)}  & =  1 .
            \end{aligned}
            \right.
        \end{equation*}
        is given by
        \[ \gen{Z(t)} = \exp \bs{\gen{W_1} \alert{∫_0^t e^{-(t - s)} \dif W_s} - t - \alert{\frac14 \br{1 - e^{-2 t}}} ~ \gen{W_1^2}} . \]
    \end{example}

    \onslide<2>
    \begin{example}[{\cite[theorem 3.3]{HwangKuoSaitô2019}}]
        The process \( \gen{Z(t)} = \exp\br{\gen{W_1} ~ W_t - t - \frac12 \gen{W_1^2} t} \) is a solution of
        \begin{equation*}
            \dif \gen{Z(t)}   =  \gen{W_1} ~ \gen{Z(t)} \dif W_t + \alert{W_1 ~ (W_t - t W_1) ~ Z(t) \dif t} ,
            \quad \gen{Z(0)}  =  1 .
        \end{equation*}
    \end{example}
\end{frame}

\begin{frame}{Generalization for anticipating drift}{\cite[theorem 4.2]{KuoShresthaSinhaSundar2022}}
    Suppose \( \ad{σ} ∈ L^2_\text{\ad{ad}}([0, 1] × Ω) \), \( γ ∈ L^2[0, 1] \), and \( ξ \) is independent of \( W \). Moreover, assume \( f ∈ C^2(ℝ) \) along with \( f, f', f'' ∈ L^1(ℝ) \). Then the solution of
    \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \gen{Z(t)}  & =  f\br{\gen{\gen{∫_0^1 γ(s) \dif W_s}}} ~ \gen{Z(t)} \dif t + \ad{σ_t} ~ \gen{Z(t)} \dif W_t  \\
                    \gen{Z(0)}  & =  ξ
        \end{aligned}
        \right.
    \end{equation*}
    in the Ayed–Kuo theory is given by
    \begin{align*}
        \gen{Z(t)} =  ξ \exp
        & \left[ ∫_0^t \ad{σ_s} \dif W_s - \frac12 ∫_0^t \ad{σ_s^2} \dif s \right.  \nonumber \\
        & \left. + ∫_0^t f\br{ \gen{∫_0^1 γ(u) \dif W_u} - \alert{∫_s^t γ(u) ~ σ_u \dif u} } \dif s \right] .
    \end{align*}

    \heading{Proof idea.} \alert{Use an ansatz} and then apply the differential formula.
\end{frame}

\begin{frame}{The squared process}
    \begin{mytheorem}[{\cite[theorem 4.3]{KuoShresthaSinhaSundar2022}}]
        Under identical conditions as before,
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{V(t)} =
                &  \left[ \ad{σ_t^2} + f\br{\gen{\gen{∫_0^1 γ(s) \dif W_s}}} \right.  \\
                &  \quad \left.  + 2 ~ γ(t) ~ \ad{σ_t} ∫_0^t \alert{f'}\br{\gen{∫_0^1 γ(u) \dif W_u} - \alert{∫_s^t γ(u) ~ σ_u \dif u}} \dif s \right] \gen{V(t)} \dif t  \\
                &  + 2 ~ \ad{σ_t} ~ \gen{V(t)} \dif W_t , \\
                \gen{V(0)}  = & ~ ξ^2
            \end{aligned}
            \right.
        \end{equation*}
        is solved by \( \gen{Z^2} \), where \( \gen{Z} \) is given as before.
    \end{mytheorem}

    % \heading{Remark.} The derivative of \( f \) appears in the stochastic differential equation.

    \heading{Proof idea.} \alert{Use an ansatz} and then apply the differential formula.
\end{frame}



\subsection{Solutions using a novel braiding technique}

\begin{frame}{Setup}
    \begin{itemize}
        \item  \heading{Goal.} Under reasonable conditions on \( γ \), \( σ \), \( f \), and \( ξ \), find the solution of
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  f\br{\gen{\gen{∫_0^1 γ(s) \dif W_s}}} \gen{Z(t)} \dif t + σ(t) ~ \gen{Z(t)} \dif W_t  \\
                     \gen{Z(0)}  & =  ξ .
            \end{aligned}
            \right.
        \end{equation*}

        \item  In Ayed–Kuo theory, the solution is
        \begin{align*}
            \gen{Z(t)} =  ξ \exp
            & \left[ ∫_0^t σ(s) \dif W_s - \frac12 ∫_0^t σ(s)^2 \dif s \right.  \\
            & \left. + ∫_0^t f\br{ \gen{∫_0^1 γ(u) \dif W_u} - \alert{∫_s^t γ(u) ~ σ(u) \dif u} } \dif s \right] .
        \end{align*}

        \item  \heading{Question.} Can we do this without an ansatz?

        \pause

        \item  \heading{Inspiration.} Trotter's product formula (\cite{Trotter1959}).
    \end{itemize}
\end{frame}

\begin{frame}{Skorokhod integral}
    \begin{itemize}
        \item  The \emph{stochastic derivative} \( \Dif \) allows us to differentiate certain random variables w.r.t. \( ω \).

        \item  The \emph{Skorokhod integral} \( δ \) is defined as the adjoint of \( \Dif \).

        \item  \( L^2_\text{\ad{ad}}\br{[0, 1] × Ω} ⊂ \operatorname{dom}(δ) \), and for any \( u ∈ L^2_\text{\ad{ad}}\br{[0, 1] × Ω} \), we have
        \[ δ(u) = ∫_0^1 u_t \dif W_t , \]
        where the right side is in the sense of Itô (\cite[proposition 1.3.4]{Nualart2006}).

        \item  Ayed–Kuo integral \( ≡ \) Skorokhod integral (\cite[theorem 2.3]{PeterParczewski2017}).
    \end{itemize}
\end{frame}

\begin{frame}{Simple anticipating SDE}
    For \( σ ∈ L^2[0, 1] \), fix the family of translation \( A_t : 𝒞_0 → 𝒞_0 \) in the Cameron–Martin direction
    \[ (A_t(ω))_s  =  ω_s - ∫_0^{t ∧ s} σ(u) \dif u . \]

    \begin{mytheorem}[{\cite[lemma 4.8]{KuoShresthaSinhaSundar2022}}]
        Suppose \( σ ∈ L^2[0, 1] \) and \( \gen{ξ} ∈ L^p(Ω) \) for some \( p > 2 \). Then
        \begin{equation*}
            \left\{
            \begin{aligned}
                \dif \gen{Z(t)}  & =  σ(t) ~ \gen{Z(t)} \dif W_t  \\
                     \gen{Z(0)}  & =  \gen{ξ} ,
            \end{aligned}
            \right.
        \end{equation*}
        in the Skorokhod sense has the unique solution
        \[ \gen{Z(t)} =  (\gen{ξ} ∘ A_t) ~ \ad{ℰ_t} . \]
    \end{mytheorem}
\end{frame}

\begin{frame}{The braiding technique: idea}{\cite[section 4.2]{KuoShresthaSinhaSundar2022}}
    \begin{figure}
        \centering
        \begin{tikzpicture}[
            decoration={markings,
            mark=at position 0.6 with {\arrow{latex}}}
        ]
            % Main timeline
            \draw [->, very thick, color=gray] (-0.5,0) -- (10.5,0) node[below] {\( t \)};
            \foreach \x/\xtext in {0/t_0=0, 2/t_1, 4/t_{2}, 7/t_{n-1}, 9/t_n=t, 10/1}
                \draw [ultra thick] (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\xtext$};

            % Guide lines
            % i = 1
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (1.9,1) -- (0,2);
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (1.9,2) -- (2.1,1);
            % i = 2
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (3.9,1) -- (2.1,2);
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (3.9,2) -- (4.1,1);
            % i = k
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (4.9,1.5) -- (4.1,2);
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (6.9,1) -- (6,1.5);
            % i = n
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (6.9,2) -- (7.1,1);
            \draw [very thick, densely dotted, color=Thistle, postaction={decorate}] (8.9,1) -- (7.1,2);

            % X1
            \draw [very thick, color=Orchid, postaction={decorate}] (0,1) -- (1.9,1);
            \draw [color=Orchid] (1,0.7) node {\( Y^{(1)} \)};
            \draw [fill=Orchid] (1.9,1) circle (1.5pt);
            \draw [fill=DeepPink] (0,1) circle (3pt);
            \draw [color=DeepPink] (-0.3,1) node {\( \gen{ξ} \)};

            % Y1
            \draw [very thick, color=DarkGoldenrod, postaction={decorate}] (0,2) -- (1.9,2);
            \draw [color=DarkGoldenrod] (1,2.3) node {\( X^{(1)} \)};
            \draw [fill=DarkGoldenrod] (0,2) circle (1.5pt);
            \draw [fill=DarkGoldenrod] (1.9,2) circle (1.5pt);

            % X2
            \draw [very thick, color=Orchid, postaction={decorate}] (2.1,1) -- (3.9,1);
            \draw [color=Orchid] (3,0.7) node {\( Y^{(2)} \)};
            \draw [fill=Orchid] (2.1,1) circle (1.5pt);
            \draw [fill=Orchid] (3.9,1) circle (1.5pt);

            % Y2
            \draw [very thick, color=DarkGoldenrod, postaction={decorate}] (2.1,2) -- (3.9,2);
            \draw [color=DarkGoldenrod] (3,2.3) node {\( X^{(2)} \)};
            \draw [fill=DarkGoldenrod] (2.1,2) circle (1.5pt);
            \draw [fill=DarkGoldenrod] (3.9,2) circle (1.5pt);

            % Forward time
            \draw [fill=Orchid] (4.1,1) circle (1.5pt);
            \draw [very thick, color=Orchid, postaction={decorate}] (4.1,1) -- (5,1);
            \draw [very thick, color=DarkGoldenrod,  postaction={decorate}] (4.1,2) -- (5,2);
            \draw [fill=DarkGoldenrod] (4.1,2) circle (1.5pt);

            % Backward time
            \draw [very thick, color=Orchid, postaction={decorate}] (6,1) -- (6.9,1);
            \draw [very thick, color=DarkGoldenrod, postaction={decorate}] (6,2) -- (6.9,2);
            \draw [fill=DarkGoldenrod] (6.9,2) circle (1.5pt);
            \draw [fill=Orchid] (6.9,1) circle (1.5pt);

            % Yn
            \draw [very thick, color=Orchid, postaction={decorate}] (7.1,1) -- (8.9,1);
            \draw [color=Orchid] (8,0.7) node {\( Y^{(n)} \)};
            \draw [fill=Orchid] (7.1,1) circle (1.5pt);
            \draw [fill=Orchid] (8.9,1) circle (1.5pt);

            % Xn
            \draw [very thick, color=DarkGoldenrod, postaction={decorate}] (7.1,2) -- (8.9,2);
            \draw [color=DarkGoldenrod] (8,2.3) node {\( X^{(n)} \)};
            \draw [fill=DarkGoldenrod] (7.1,2) circle (1.5pt);
            \draw [fill=DeepPink] (8.9,2) circle (3pt);
            \draw [color=DeepPink] (9.3,2) node {\( Z \)};

            \draw[color=Black] (5.5,1.5) node  {\( \dotsb \)};
            % Setup and bounding box
            % \clip(-2,-1) rectangle (9,3);
            % \draw (current bounding box.north east) rectangle (current bounding box.south west);
        \end{tikzpicture}
    \end{figure}

    For \( u ∈ [t_{k-1}, t_k] \),
    \begin{align*}
        \dif \sde{Y^{(k)}_u}  & =  σ(u) ~ \sde{Y^{(k)}_u} \dif W_u  &
        \dif \ode{X^{(k)}_u}  & =  f\br{\gen{∫_0^1 γ(u) \dif W_u}} ~ \ode{X^{(k)}_u} \dif s  \\
        \sde{Y^{(k)}_{t_{k-1}}}  & =  \ode{X^{({k-1})}_{t_{k-1}}}  &
        \ode{X^{(k)}_{t_{k-1}}}  & =  \sde{Y^{(k)}_{t_k}}
    \end{align*}
\end{frame}

\begin{frame}{The braiding technique: algorithm}{\cite[section 4.2]{KuoShresthaSinhaSundar2022}}
    \begin{enumerate}
        \item  Consider a partition \( Δ_n = \bc{t_0 = 0, t_1, \dotsc, t_n = t} \) of \( [0, t] \).
        \item  On each subinterval, iteratively solve the following:
        \begin{enumerate}
            \item  the \sde{SDE} with only diffusion
            \begin{equation*}
                \left\{
                \begin{aligned}
                       \dif \sde{Y^{(k)}_u}  & =  σ(u) ~ \sde{Y^{(k)}_u} \dif W_u ,  \quad  u ∈ [t_{k-1}, t_k] , \\
                    \sde{Y^{(k)}_{t_{k-1}}}  & =  \ode{X^{({k-1})}_{t_{k-1}}} , \text{ and}
                \end{aligned}
                \right.
            \end{equation*}

            \item  the \ode{ODE} with only the drift
            \begin{equation*}
                \left\{
                \begin{aligned}
                       \dif \ode{X^{(k)}_u}  & =  f\br{\gen{∫_0^1 γ(u) \dif W_u}} ~ \ode{X^{(k)}_u} \dif s ,  \quad  u ∈ [t_{k-1}, t_k] , \\
                    \ode{X^{(k)}_{t_{k-1}}}  & =  \sde{Y^{(k)}_{t_k}} .
                \end{aligned}
                \right.
            \end{equation*}
        \end{enumerate}
        For the first step, use \( \sde{Y^{(1)}_0} = \gen{ξ} \).

        \item  The limit of \( \ode{X^{(n)}} \) as \( n → ∞ \) gives us the required solution \( \gen{Z} \).
    \end{enumerate}
\end{frame}

\begin{frame}{Existence lemma}{\cite[lemma 4.9]{KuoShresthaSinhaSundar2022}}
    Let \( \gen{ξ} ∈ L^p(Ω) \) for some \( p > 2 \). Consider the \( k \)th subinterval \( u ∈ [t_{k-1}, t_k] \) for any \( k ∈ [n] \), and define \( \sde{Y^{(k)}} \) and \( \ode{X^{(k)}} \) as above. Then there exists a set \( Ω_k ⊆ Ω \) with \( \Pr\br{Ω_k} = 1 \) such that on \( Ω_k \), we have
    \[ \ode{X^{(k)}_{t_k}} =  (\gen{ξ} ∘ A_0^{t_k}) ~ E_0^{t_k} ~ ∏_{i = 1}^k (\gen{g_{t_{i-1}}^{t_i}} ∘ A_{t_i}^{t_k}) , \]
    where
    \begin{align*}
        \gen{g_u^v}  & =  \exp\bs{(v - u) ~ f\br{ \gen{∫_0^1 γ(u) \dif W_u }}},  \quad  \text{ and}  \\
        E_u^v  & =  \exp\bs{∫_u^v σ(s) \dif W_s - \frac12 ∫_u^v σ(s)^2 \dif s} .
    \end{align*}
\end{frame}

\begin{frame}{General result}{\cite[theorem 4.10]{KuoShresthaSinhaSundar2022}}
    Suppose \( σ, γ ∈ L^2[0, 1] \), \( f: ℝ → ℝ \), and \( \gen{ξ} ∈ L^p(Ω) \) for some \( p > 2 \). Then the \alert{unique} solution of
    \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \gen{Z(t)}  & =  f\br{\gen{\gen{∫_0^1 γ(s) \dif W_s}}} \gen{Z(t)} \dif t + σ(t) ~ \gen{Z(t)} \dif W_t  \\
                \gen{Z(0)}  & =  \gen{ξ} .
        \end{aligned}
        \right.
    \end{equation*}
    in the Skorokhod sense is
    \begin{align*}
        \gen{Z(t)}  =  (\gen{ξ} ∘ A_0^t) \exp
        &  \left[ ∫_0^t σ(s) \dif W_s - \frac12 ∫_0^t σ(s)^2 \dif s \right.  \\
        &  \left. + ∫_0^t f\br{ \gen{∫_0^1 γ(u) \dif W_u} - \alert{∫_s^t γ(u) ~ σ(u) \dif u} } \dif s \right] .
    \end{align*}
\end{frame}



\subsection{Large deviation principles}

\begin{frame}{Large deviation principles}
    \heading{Basics}
    \begin{itemize}
        \item  Allows us to calculate probabilities of rare events that decay exponentially.
        \item  Heuristically, \( \Pr\bc{X^ϵ ∈ \dif x} ≍ \exp\br{-\frac{I(x)}{ϵ}} \dif x \).
        \item  More rigorously, \( ϵ \log\Pr\bc{X^ϵ ∈ E} → - \inf_E I(x) \) as \( ϵ → 0 \).
    \end{itemize}

    \pause

    \heading{Define}
    \begin{itemize}
        \item  \( 𝒞_κ = \bc{f: [0, 1] → ℝ \given f \text{ continuous}, f(0) = κ} \)
        \item  \( ℋ^1 = \bc{f ∈ 𝒞_0 \given f' ∈ L^2[0, 1]} \)
    \end{itemize}

    \pause

    \begin{mytheorem}[\cite{Schilder1966}]
        The family \( \br{\sqrt{ϵ} W}_{ϵ > 0} \) on \( \br{𝒞_0, \norm{⋅}_∞} \) satisfies LDP with rate function
        \begin{equation*}
            I(ω) =
            \begin{cases}
                \frac12 ∫_0^1 \abs{ω'(t)}^2 \dif t  &  \text{if } ω ∈ ℋ^1 , \\
                ∞  &  \text{otherwise} .
            \end{cases}
        \end{equation*}
    \end{mytheorem}
\end{frame}

% \begin{frame}{Tools}{Continuity principle}
%     Given
%     \begin{itemize}
%         \item  \( 𝒳, 𝒴 \) Polish spaces,
%         \item  \( f: 𝒳 → 𝒴 \) is continuous,
%         \item  \( \br{μ^ϵ}_{ϵ > 0} \) are probability measures on \( 𝒳 \),
%         \item  \( \br{μ^ϵ}_{ϵ > 0} \) satisfy LDP with rate \( I: 𝒳 → [0, ∞] \).
%     \end{itemize}
%     Then \( \br{μ^ϵ ∘ \inv{f}}_{ϵ > 0} \) on \( 𝒴 \) satisfy LDP with rate \( J: 𝒴 → [0, ∞] \).
% \end{frame}

\begin{frame}{LSDEs with anticipating coefficients}{\alert{Constant} initial conditions: setup}
    Suppose \( σ \) and \( γ \) are deterministic functions of bounded variation on \( [0, 1] \). Moreover, suppose \( f ∈ C^2(ℝ) \) is Lipschitz continuous along with \( f, f', f'' ∈ L^1(ℝ) \). For a fixed \( κ ∈ ℝ \), consider the family of linear stochastic differential equations with parameter \( ϵ > 0 \) given by
    \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \gen{Z^ϵ_κ(t)}  & =  f\br{\sqrt{ϵ} \gen{∫_0^1 γ(s) \dif W_s}} \gen{Z^ϵ_κ(t)} \dif t + \sqrt{ϵ} σ(t) \gen{Z^ϵ_κ(t)} \dif W_t  \\
                \gen{Z^ϵ_κ(0)}  & =  κ ,
        \end{aligned}
        \right.
    \end{equation*}
    Then the unique solutions are given by
    \begin{align*}
        \gen{Z^ϵ_κ(t)}  =  κ \exp
        &  \left[ \sqrt{ϵ} ∫_0^t σ(s) \dif W_s - \frac{ϵ}{2} ∫_0^t σ(s)^2 \dif s \right.  \nonumber \\
        &  \left. + ∫_0^t f\br{ \sqrt{ϵ} \gen{∫_0^1 γ(u) \dif W_u} - ϵ \alert{∫_s^t γ(u) ~ σ(u) \dif u} } \dif s \right] .
    \end{align*}
\end{frame}

\begin{frame}{LSDEs with anticipating coefficients}{\alert{Constant} initial conditions: large deviation principle}
    \begin{mytheorem}[{\cite[theorem 5.7]{KuoShresthaSinhaSundar2022}}]
        The family \( \br{\gen{Z^ϵ_κ}}_{ϵ > 0} \) follows LDP on \( \br{𝒞_κ, \norm{⋅}_∞} \) with the rate function
        \[ J(y) = \inf \bc{I ∘ \inv{θ} (y)} , \]
        where \( I \) is the Schilder's rate function and the continuous function \( θ: 𝒞_0 → 𝒞_κ \) is defined by
        \begin{align*}
            θ(x)  =  κ \exp
            &  \left[ ∫_0^t σ(s) \dif x(s) - \frac{ϵ}{2} ∫_0^t σ(s)^2 \dif s \right.  \\
            &  \left. + ∫_0^t f\br{ ∫_0^1 γ(u) \dif x(u) - ϵ ∫_s^t γ(u) ~ σ(u) \dif u } \dif s \right] ,
        \end{align*}
    \end{mytheorem}
\end{frame}

\begin{frame}{LSDEs with anticipating coefficients}{\alert{Random} initial conditions: setup}
    Suppose \( σ, γ, f \) are as before. Consider the family of linear stochastic differential equations with parameter \( ϵ > 0 \) given by
    \begin{equation*}
        \left\{
        \begin{aligned}
            \dif \gen{Z^ϵ_ξ(t)}  & =  f\br{\sqrt{ϵ} \gen{∫_0^1 γ(s) \dif W_s}} \gen{Z^ϵ_ξ(t)} \dif t + \sqrt{ϵ} σ(t) ~ \gen{Z^ϵ_ξ(t)} \dif W_t  \\
                \gen{Z^ϵ_ξ(0)}  & =  ξ^ϵ ,
        \end{aligned}
        \right.
    \end{equation*}
    where each \( ξ^ϵ \) is a random variable independent of the Wiener process \( W \). Then the unique solutions are given by
    \begin{align*}
        \gen{Z^ϵ_ξ(t)} =  ξ^ϵ \exp
        &  \left[ \sqrt{ϵ} ∫_0^t σ(s) \dif W_s - \frac{ϵ}{2} ∫_0^t σ(s)^2 \dif s \right.  \nonumber \\
        &  \left. + ∫_0^t f\br{ \sqrt{ϵ} \gen{∫_0^1 γ(u) \dif W_u} - ϵ \alert{∫_s^t γ(u) ~ σ(u) \dif u} } \dif s \right] .
    \end{align*}
\end{frame}

\begin{frame}{LSDEs with anticipating coefficients}{\alert{Random} initial conditions: large deviation principle}
    \begin{mytheorem}[{\cite[theorem 5.8]{KuoShresthaSinhaSundar2022}}]
        Let \( κ ∈ ℝ \) and
        \[ \alert{ \lim_{ϵ → 0} ϵ \log \E\br{ξ^ϵ - κ}^2 = -∞ }. \]
        Moreover, assume that the functions \alert{\( f, f', σ, γ \) are all bounded}. Then the family \( \br{\gen{Z^ϵ_ξ}}_{ϵ > 0} \) follows LDP on \( \br{𝒞_κ, \norm{⋅}_∞} \) with the rate function
        \[ J(y) = \inf \bc{I ∘ \inv{θ} (y)} , \]
        where \( I \) is the Schilder's rate function and \( θ: 𝒞_0 → 𝒞_κ \) is the continuous function shown before.
    \end{mytheorem}
\end{frame}




\section{Epilogue}

\begin{frame}{Summary}
    \begin{table}[ht]
        \rowcolors{1}{}{IndianRed!5}
        \begin{tabular}{lcc}
            \toprule
            property  &  classical theory  &  Ayed–Kuo theory  \\
            \midrule
            definition  &  Itô's integral   &  Ayed–Kuo integral  \\
            well-defined  &  \( ✓ \)  &  \( ✓ \)  \\
            linearity  &  \( ✓ \)  &  \( ✓ \)  \\
            mean \( 0 \)  &  \( ✓ \)  &  \( ✓ \)  \\
            isometry  &  Itô's isometry  &  \good{extension}  \\
            martingale  &  martingales  &  near-martingales  \\
            stopped processes  &  Doob's OST  &  \good{near-martingale OST}  \\
            differential equations  &  SDEs  &  \good{anticipating SDEs}  \\
            LDP  &  Freidlin–Wentzell theory  &  \good{specific results}  \\
            inequalities  &  Doob's martingale inequality  &  \bad{open problem}  \\
            memory  &  Markov processes  &  \bad{open problem}  \\
            measure equivalence  &  Girsanov's theorem  &  \bad{open problem}  \\
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}

\begin{frame}{Main contributions}
    \begin{enumerate}
        \item  Extension of Itô's isometry
        \item  Near-martingale optional stopping theorem
        \item  LSDEs with anticipating initial conditions
        \begin{enumerate}
            \item  Solutions
            \item  Conditionals
        \end{enumerate}
        \item  LSDEs with anticipating coefficients
        \begin{enumerate}
            \item  Solutions in Ayed–Kuo theory
            \item  Solutions via a novel braiding technique
            \item  Large deviation principles
        \end{enumerate}
    \end{enumerate}
\end{frame}

\begin{frame}[c]
	\begin{center}
		{\huge Thank you!}
	\end{center}
\end{frame}




\appendix

\begin{frame}<presentation>[allowframebreaks]{Bibliography}
    \renewcommand*{\bibfont}{\footnotesize}    % Reduce font size
	\printbibliography
\end{frame}

\begin{frame}{Appendix A: Malliavin calculus}
    \begin{itemize}
        \item  \heading{Goal.} Differentiate a stochastic process w.r.t. \( ω \).
        \item  Formalized by Malliavin calculus.
        \item  Let \( W(h) = ∫_0^1 h(t) \dif W_t \). Let \( 𝒮 \) denote the class of \emph{smooth random variables} such that a random variable \( F ∈ 𝒮 \) has the form
        \[ F = f\br{W(h_1), \dotsc, W(h_n)} , \]
        where \( f ∈ C^∞_p(ℝ^n) \), and \( h_1, \dotsc, h_n ∈ L^2[0, 1] \) for any natural number \( n \).
        \item  Then the \emph{stochastic derivative} of \( F ∈ 𝒮 \) is given by
        \[ \Dif F = ∑_{i = 1}^n \frac{∂ f}{∂ x_i}\br{W(h_1), \dotsc, W(h_n)} h_i . \]
        \item  \emph{Example 1.} \( \Dif W_{\frac12} = 𝟙_{\bs{0, \frac12}} \), since \( W_{\frac12} = ∫_0^1 𝟙_{\bs{0, \frac12}} \dif W_t \).
        \item  \heading{Example.} \( \Dif W(h) = h \) and \( \Dif W(h)^2 = 2 W(h) ~ h \).
        \item  (Integration-by-parts)  For \( F ∈ 𝒮 \) and \( h ∈ L^2[0, 1] \), we have
        \[ \E\br{\ba{\Dif F, h}} = \E\br{F W(h)} . \]
    \end{itemize}
\end{frame}

\begin{frame}{Appendix B: Skorokhod integral}
    \begin{itemize}
        \item  The \emph{Skorokhod stochastic integral} or \emph{divergence operator}\index{divergence operator} \( δ \) is defined as the adjoint of the stochastic derivative operator \( \Dif \).

        \item  Let \( F_i ∈ 𝒮 \) and \( h_i ∈ L^2[0, 1] \) for all \( i ∈ [n] \). For \( u(t) = ∑_{i = 1}^n F_i ~ h_i(t) \), we have
        \[ δ(u) = ∑_{i = 1}^n F_i ~ W\br{h_i(t)} - ∑_{i = 1}^n (\Dif F_i)(t) ~ h_i(t) \dif t . \]

        \item  \( L^2_\text{\ad{ad}}\br{[0, 1] × Ω} ⊂ \operatorname{dom}(δ) \), and for any \( u ∈ L^2_\text{\ad{ad}}\br{[0, 1] × Ω} \), we have
        \[ δ(u) = ∫_0^1 u_t \dif W_t , \]
        where the right side is in the sense of Itô (\cite[proposition 1.3.4]{Nualart2006}).

        \item  Ayed–Kuo integral \( ≡ \) Skorokhod integral (\cite[theorem 2.3]{PeterParczewski2017}).
    \end{itemize}
\end{frame}

\end{document}
