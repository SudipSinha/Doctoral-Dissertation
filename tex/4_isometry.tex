% !TeX root = ../dissertation.tex

\section{Motivation}
\footnotetextonly{This chapter previously appeared in the following open-access journal article: \fullcite{KuoShresthaSinha2021isometry}.}

We remarked in \cref{sec:ItÃ´_integral} that ItÃ´'s isometry\index{isometry!ItÃ´} forms the backbone of ItÃ´'s integral. Therefore, for any theory that extends ItÃ´'s theory, it is important to know if the isometry holds. The focus of this chapter will be to derive an identity in Ayedâ€“Kuo theory that reduces to ItÃ´ isometry for adapted processes.

Should we expect ItÃ´'s isometry to hold identically for the Ayedâ€“Kuo integral? From white noise distribution theory\index{white noise distribution theory}, we expect otherwise. We take a brief detour to explore this idea.

Recall that the white nose approach to anticipating stochastic integral is given by the Hitsudaâ€“Skorokhod integral\index{integral!Hitsudaâ€“Skorokhod}
\[ âˆ«_a^b âˆ‚_t^* Z(t) \dif t , \]
where \( Z \) is a Wiener functional and \( âˆ‚_t^* \) is the adjoint of the white noise differential operator \( âˆ‚_t \) \cite[see][page 107]{Kuo1996}. (For a detailed description of the Hitsudaâ€“Skorokhod integral, see \cite[chapter 5]{Kuo1996}.) Essentially, \cite[theorem 13.16]{Kuo1996} asserts that under certain conditions on \( Z \), the white noise integral \( âˆ«_a^b âˆ‚_t^* Z(t) \dif t \) is a Hitsudaâ€“Skorokhod integral, and we have
\begin{equation}  \label{eqn:Hitsudaâ€“Skorokhod_identity}
    \E\bs{\br{âˆ«_a^b âˆ‚_t^* Z(t) \dif t}^2}
    = âˆ«_a^b \E\bs{Z(t)^2} \dif t
    +  âˆ«_a^b âˆ«_a^b \E\bs{âˆ‚_t Z(s) ~ âˆ‚_s Z(t)} \dif s \dif t .
\end{equation}

Moreover, from white noise analysis, we have the symbolic expression
\begin{equation}  \label{eqn:white_noise_derivative_W}
    âˆ‚_t W_s = ğŸ™_{\bc{t < s}} .
\end{equation}
We can verify this expression using the last line on \cite[page 103]{Kuo1996} and the representation of Wiener process in \cite[page 254]{Kuo1996}.

Now, let \( f \) and \( Ï• \) be \( C^1 \)-functions on \( â„ \) and consider the Wiener functional
\begin{equation} \label{eqn:Z_special_form}
    Z(t) = f(W_t) ~ Ï• (W_b - W_t),  \quad  t âˆˆ [a, b]
\end{equation}
Suppose \( s < t \). Then by the chain rule and \cref{eqn:white_noise_derivative_W}, we have
\begin{align}  \label{eqn:âˆ‚t_Zs}
    âˆ‚_t Z(s)
    & =  f'(W_s) ~ \br{âˆ‚_t W_s} ~ Ï•(W_b - W_s)
        +  f(W_s) ~ Ï•'(W_b - W_s) ~ \br{âˆ‚_t (W_b - W_s)}  \nonumber \\
    & =  f(W_s) ~ Ï•'(W_b - W_s) .
\end{align}
Similarly,
\begin{equation}  \label{eqn:âˆ‚s_Zt}
    âˆ‚_s Z(t)  =  f(W_t) ~ Ï•'(W_b - W_t) .
\end{equation}

Putting \cref{eqn:Hitsudaâ€“Skorokhod_identity,eqn:Z_special_form,eqn:âˆ‚t_Zs,eqn:âˆ‚s_Zt} together, we get
\begin{align}  \label{eqn:identity_white_noise}
    &  \E\bs{ \br{âˆ«_a^b âˆ‚_t^*\br{f(W_t) ~ Ï•(W_b - W_t)} \dif t}^2}  =  âˆ«_a^b \E\bs{ f(W_t)^2 ~ Ï•(W_b - W_t)^2 } \dif t  \nonumber \\
    &  \quad +  2 âˆ«_a^b âˆ«_a^t \E\bs{ f(W_s) ~ Ï•'(W_b - W_s) ~ f'(W_t) ~ Ï•(W_b - W_t) } \dif s \dif t .
\end{align}
But for a Wiener functional \( Z(t) = f(W_t) ~ Ï•(W_b - W_t) \), its Hitsudaâ€“Skorokhod integral turns out to be the same as the Ayedâ€“Kuo integral, namely
\begin{equation}\label{eqn:Hitsudaâ€“Skorokhod_equals_Ayedâ€“Kuo}
    \int_a^b âˆ‚_t^*\br{f(W_t) ~ Ï•(W_b - W_t)} \dif t
    =  \int_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t.
\end{equation}
Therefore, \cref{eqn:identity_white_noise,eqn:Hitsudaâ€“Skorokhod_equals_Ayedâ€“Kuo}) yields the following identity
\begin{align}  \label{eqn:identity}
    &  \E\bs{ \br{âˆ«_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t}^2}  =  âˆ«_a^b \E\bs{ f(W_t)^2 ~ Ï•(W_b - W_t)^2 } \dif t  \nonumber \\
    &  \quad +  2 âˆ«_a^b âˆ«_a^t \E\bs{ f(W_s) ~ Ï•'(W_b - W_s) ~ f'(W_t) ~ Ï•(W_b - W_t) } \dif s \dif t .
\end{align}
which is what we expect for the Ayedâ€“Kuo integral.



\section{Previous attempts}
It is important to note that this is not the first attempt to formulate such a result. In fact, in \cite[theorem 3.1]{KuoSaeTangSzozda2013}, the authors demonstrated that \cref{eqn:identity} holds under strong assumptions of \( f \) and \( Ï• \) being analytic on the entire real line and having bounded derivatives.

However, the earlier result had significant drawbacks. First, the assumptions on \( f \) and \( Ï• \) are quite restrictive as noted. Second, the proof of the result is quite lengthy, and involves tedious computations using binomial expansion of the function \( f \) and \( Ï• \). Third, the proof did not utilize the core idea of the Ayedâ€“Kuo integral, that is, to evaluate adapted integrands at the left-endpoints and the instantly-independent processes at the right-endpoints of the intervals. Our new proof exploits this nature of the integral and resolves the stated shortcomings. We also do not imposing any restrictions on \( f \) and \( Ï• \) outside of what is required for \cref{eqn:identity} to be well-defined.



\section{Identity for the simple case}  \label{sec:isometry_product}

In the proof of \cref{thm:isometry_extension_product} below, for \( a â‰¤ s â‰¤ t â‰¤ b \), we shall use the Ïƒ-algebras
\begin{align*}
    â„±_s  & =  Ïƒ\bc{W_u \given a â‰¤ u â‰¤ s} , \\
    ğ’¢^t  & =  Ïƒ\bc{W_b - W_v | t â‰¤ v â‰¤ b} , \text{ and} \\
    â„‹_s^t  & =  Ïƒ\br{â„±_s âˆª ğ’¢^t} .
\end{align*}
We call \( \{ â„±_s: s âˆˆ [a, b] \} \) the \emph{forward}-filtration\index{filtration!forward} and \( \{ ğ’¢^t: t âˆˆ [a, b] \} \) the \emph{backward}\index{filtration!backward} or \emph{counter}-filtration\index{filtration!counter} generated by the Wiener process. Taking conditional expectation judiciously with respect to the \emph{separation Ïƒ-algebra}\index{sigma@Ïƒ-algebra!separation} \( â„‹_s^t \) plays a crucial part in the proof of the following theorem.


\begin{theorem}  \label{thm:isometry_extension_product}
    Suppose \( f, Ï• âˆˆ C^1(â„) \) such that \( f(W_t) ~ Ï•(W_b - W_t), f(W_t) ~ Ï•'(W_b - W_t), f'(W_t) ~ Ï•(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \). Moreover, assume the stronger condition of convergence in \( L^2(Î©) \) instead of a convergence in probability for the definition of the Ayedâ€“Kuo integral. Then \( \E\bs{ âˆ«_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t } = 0 \), and
    \begin{align}
        &  \E\bs{ \br{âˆ«_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t}^2}  =  âˆ«_a^b \E\bs{ f(W_t)^2 ~ Ï•(W_b - W_t)^2 } \dif t  \nonumber \\
        &  \quad +  2 âˆ«_a^b âˆ«_a^t \E\bs{ f(W_s) ~ Ï•'(W_b - W_s) ~ f'(W_t) ~ Ï•(W_b - W_t) } \dif s \dif t . \label{eqn:isometry_extension_product}
    \end{align}
\end{theorem}

\begin{remark}
    For the right-hand side of \cref{eqn:isometry_extension_product} to be well-defined, we need the two integrals to be individually well-defined.

    For the first integral, we directly see that the integral is well-defined if \( f(W_t) ~ Ï•(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \). For conciseness, we write \( f_t = f(W_t) \), \( Ï•_t = Ï•(W_b - W_t) \), and similarly their corresponding derivatives. Using this notation, for the second integral, we can use Cauchyâ€“Schwarz inequality to get
    \begin{align*}
        & âˆ«_a^b âˆ«_a^t \E\bs{ f_s ~ Ï•_s' ~ f_t' ~ Ï•_t} \dif s \dif t  \\
        & â‰¤  âˆ«_a^b âˆ«_a^t \br{ \E\bs{ \abs{f_s ~ Ï•_s'}^2 }}^\frac12 \br{ \E\bs{ \abs{f_t' ~ Ï•_t}^2 }}^\frac12 \dif s \dif t  \\
        & â‰¤  âˆ«_a^b \br{ \E\bs{ \abs{f_s ~ Ï•_s'}^2 }}^\frac12 \dif s âˆ«_a^b \br{ \E\bs{ \abs{f_t' ~ Ï•_t}^2 }}^\frac12 \dif t  \\
        & â‰¤  (b - a) \br{ âˆ«_a^b \E\bs{ \abs{f_s ~ Ï•_s'}^2 } \dif s }^\frac12
        \br{ âˆ«_a^b \E\bs{ \abs{f_t' ~ Ï•_t}^2 } \dif t }^\frac12 ,
    \end{align*}
    where we used the Schwarz's inequality in the last step.

    Combining these results, we see that a sufficient condition for the second integral to exist is \( f(W_t) ~ Ï•(W_b - W_t), f(W_t) ~ Ï•'(W_b - W_t), f'(W_t) ~ Ï•(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \).
\end{remark}

\begin{remark}
    In the proof of ItÃ´'s isometry, one typically takes conditional expectation with respect to the Ïƒ-algebra \( â„±_s \) in a simple way. On the other hand, our proof requires conditioning with respect to the Ïƒ-algebra \( â„‹_s^t \) in a very specific manner.
\end{remark}

\begin{proof}
    For notational convenience, let
    \begin{align*}
        \Del W_k   & =  W_{t_k} - W_{t_{k-1}} , \\
        \Del t_k   & =  t_k - t_{k - 1} , \\
        f_{k - 1}  & =  f(W_{t_{k-1}}) , \text{and}  \\
               Ï•_k & =  Ï•(W_b - W_{t_k}) .
    \end{align*}
    Note that in this proof, we use \( Ï•_k \) (subscript \( k \)) to represent the time even though \( Ï• \) is instantly-independent. We use superscripts only for powers. We also assume that \( \norm{Î _n} â†’ 0 \) as \( n â†’ 0 \) as usual.

    By the definition of the anticipating stochastic integral, we get
    \begin{equation*}
        âˆ«_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t
        = \lim_{n â†’ âˆ} âˆ‘_{i = 1}^n f_{i-1} Ï•_i \Del W_i ,
    \end{equation*}
    where the limit is in \( L^2(Î©) \).
    Therefore, for the mean, we have
    \begin{align*}
        \E\bs{ âˆ«_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t }
        & =  \lim_{n â†’ âˆ} âˆ‘_{i = 1}^n \E\bs{ f_{i-1} ~ Ï•_i \Del W_i }  \\
        & =  \lim_{n â†’ âˆ} âˆ‘_{i = 1}^n \E\bs{ \E\br{ f_{i-1} ~ Ï•_i \Del W_i \given â„‹_{t_{j-1}}^{t_j} } }  \\
        & =  \lim_{n â†’ âˆ} âˆ‘_{i = 1}^n \E\bs{ f_{i-1} ~ Ï•_i ~ \cancelto{0}{\E\br{\Del W_i}} }  \\
        & =  0 ,
    \end{align*}
    where we used the fact that \( f_{i-1} \) and \( Ï•_i \) are \( â„‹_{t_{j-1}}^{t_j} \)-measurable, and \( \Del W_i \) is independent of \( â„‹_{t_{j-1}}^{t_j} \).

    For the variance,
    \begin{align*}
        &  \E\bs{ \br{âˆ«_a^b f(W_t) ~ Ï•(W_b - W_t) \dif W_t}^2}  \\
        &  =  \lim_{n â†’ âˆ} âˆ‘_{i = 1}^n âˆ‘_{j = 1}^n \E\bs{ f_{i-1} ~ Ï•_i f_{j-1} ~ Ï•_j \Del W_i \Del W_j}  \\
        &  =  \lim_{n â†’ âˆ} âˆ‘_{i = 1}^n \E\bs{ f_{i-1}^2 ~ Ï•_i^2 \br{\Del W_i}^2}  +  2 \lim_{n â†’ âˆ} âˆ‘_{j = 1}^n âˆ‘_{i = 1}^j \E\bs{ f_{i-1} ~ Ï•_i f_{j-1} ~ Ï•_j \Del W_i \Del W_j}  \\
        &  =:  D_0 + 2 D_1 ,
    \end{align*}
    where we separated the sum into diagonal and off-diagonal elements in the penultimate step and used the symmetry of \( i < j \) and \( i > j \).

    First we focus on the diagonal elements. Note that \( \Del W_i \) is independent of both \( â„±_{t_{i-1}} \) and \( ğ’¢^{t_i} \). Moreover, \( f_{i-1} \) is \( â„±_{t_{i-1}} \)-measurable and independent of \( ğ’¢^{t_i} \). Similarly \( Ï•_i \) is \( ğ’¢^{t_i} \)-measurable and independent of \( â„±_{t_{i-1}} \). Therefore, by taking conditional expectation with respect to \( â„±_{t_{i-1}} \), we get
    \begin{align*}
        \E\bs{ f_{i-1}^2 ~ Ï•_i^2 \br{\Del W_i}^2}
        &=  \E\bs{  \E\br{ f_{i-1}^2 ~ Ï•_i^2 \br{\Del W_i}^2 \given â„±_{t_{i-1}} }}  \\
        &=  \E\bs{ f_{i-1}^2 ~ \E\br{ Ï•_i^2 \br{\Del W_i}^2 \given  â„±_{t_{i-1}} }}  \\
        &=  \E\bs{ f_{i-1}^2 } ~ \E\bs{ Ï•_i^2 \br{\Del W_i}^2 } .
    \end{align*}
    Similarly, taking conditional expectation with respect to \( ğ’¢^{t_i} \) gives us
    \begin{align*}
        \E\bs{ Ï•_i^2 \br{\Del W_i}^2 }
        &=  \E\bs{  \E\br{ Ï•_i^2 \br{\Del W_i}^2 \given ğ’¢^{t_i} }}  \\
        &=  \E\bs{ Ï•_i^2 ~ \E\br{ \br{\Del W_i}^2 \given  ğ’¢^{t_i} }}  \\
        &=  \E\bs{ Ï•_i^2 } ~ \E\bs{ \br{\Del W_i}^2 } .
    \end{align*}
    Putting it all together along with the fact that \( \E\bs{ \br{\Del W_i}^2 } = \Del t_i \), we get
    \begin{equation*}
        \E\bs{ f_{i-1}^2 ~ Ï•_i^2 \br{\Del W_i}^2}  =  \E\bs{ f_{i-1}^2 } \E\bs{ Ï•_i^2 } \Del t_i  =  \E\bs{ f(W_t)^2 Ï•(W_b - W_t)^2} \Del t_i ,
    \end{equation*}
    where we used the independence of increments of Wiener process in the last equality. Summing over \( i \) and taking limit of \( n â†’ âˆ \), we get the first term on the right side of \cref{eqn:isometry_extension_product} as
    \begin{equation*}
        D_0 = âˆ«_a^b \E\bs{ f(W_t)^2 ~ Ï•(W_b - W_t)^2} \dif t .
    \end{equation*}

    The method for the off-diagonal elements is not as direct, and we highlight the key tricks.
    \begin{description}[leftmargin=0cm]
        \item[Trick 1]  Note that \( \Del W_i \) is independent of both \( â„±_{t_{i-1}} \) and \( ğ’¢^{t_i} \), and is therefore independent of \( â„‹_{t_{i-1}}^{t_i} \). So conditioning with respect to \( â„‹_{t_{i-1}}^{t_i} \) gives us
        \begin{align*}
            \E\br{ \Del W_i \given â„‹_{t_{i-1}}^{t_i} }  & =  \E\bs{\Del W_i}  =  0 , \text{ and} \\
            \E\br{ (\Del W_i)^2 \given â„‹_{t_{i-1}}^{t_i} }  & =  \E\bs{(\Del W_i)^2}  =  \Del t_i .
        \end{align*}

        \item[Trick 2]  Consider \( W_b - W_{t_i} - \Del W_j = (W_b - W_{t_j}) + (W_{t_{j-1}} - W_{t_i}) \). Since \( W_b - W_{t_j} \) is \( ğ’¢^{t_j} \)-measurable and \( W_{t_{j-1}} - W_{t_i} \) is \( â„±_{t_{j-1}} \)-measurable, the sum \( W_b - W_{t_i} - \Del W_j \) is \( â„‹_{t_{j-1}}^{t_j} \)-measurable. By continuity of \( Ï• \), we see that \( Ï•(W_b - W_{t_i} - \Del W_j) \) is also \( â„‹_{t_{j-1}}^{t_j} \)-measurable. This allows us to conclude that
        \begin{align}
            & \E\bs{ f_{i-1} ~ Ï•(W_b - W_{t_i} - \Del W_j) ~ f_{j-1} ~ Ï•_j \Del W_i \Del W_j}  \nonumber \\
            & =  \E\bs{ \E\br{ f_{i-1} ~ Ï•(W_b - W_{t_i} - \Del W_j) ~ f_{j-1} ~ Ï•_j \Del W_i \Del W_j \given â„‹_{t_{j-1}}^{t_j} }}  \nonumber \\
            & =  \E\bs{ f_{i-1} ~ Ï•(W_b - W_{t_i} - \Del W_j) ~ f_{j-1} ~ Ï•_j \Del W_i ~ \E\br{ \Del W_j \given â„‹_{t_{j-1}}^{t_j} }}  \nonumber \\
            & =  0 . \label{eqn:Ï•_var_0}
        \end{align}
        Therefore, if we subtract the term \( \E\bs{ f_{i-1} ~ Ï•(W_b - W_{t_i} - \Del W_j) ~ f_{j-1} ~ Ï•_j \Del W_i \Del W_j} \) from the expression \( \E\bs{ f_{i-1} ~ Ï•_i f_{j-1} ~ Ï•_j \Del W_i \Del W_j} \), nothing changes. This allows us to remove the dependence of \( Ï•_i \) on \( \bc{W_t: t âˆˆ (t_{j-1}, t_j)} \). This is illustrated in \cref{fig:isometry_proof} by the dotted region of \( Ï•_i \).

        \item[Trick 3]  Using the assumption \( Ï• âˆˆ C^1(â„) \) and considering the fact that \( W_t \) is continuous and so \( \Del W_j â†’ 0 \) as \( \norm{Î _n} â†’ 0 \), we can approximate
        \begin{equation*}
            Ï•(W_b - W_{t_i}) - Ï•(W_b - W_{t_i} - \Del W_j) â‰ƒ Ï•'(W_b - W_{t_i} - \Del W_j) \Del W_j .
        \end{equation*}
        For brevity, we write \( Î˜ = Ï•'(W_b - W_{t_i} - \Del W_j) \). Note that \( Î˜ \) is \( â„‹_{t_{i-1}}^{t_i} \)-measurable.
    \end{description}

    \begin{figure}
        \centering
        \begin{tikzpicture}
            % â„‹_{t_{i-1}}^{t_i}
            \fill [RosyBrown!25] (0,0) rectangle (2,3);
            \fill [RosyBrown!25] (3,0) rectangle (8,3);
            \node (separation) at (2.5, 3.5) [RosyBrown] {\( â„‹_{t_{i-1}}^{t_i} \)};
            \draw [->, thick, color=RosyBrown] (separation.west) to [bend right=10] (  1,2.5);
            \draw [->, thick, color=RosyBrown] (separation.east) to [bend left=10 ] (5.5,2.5);

            % Main timeline
            \draw [->, very thick, color=gray] (-2,0) -- (9,0) node[below] {\( t \)};
            \foreach \x/\xtext in {-1/0, 0/a, 2/t_{i-1}, 3/t_i, 5/t_{j-1}, 6/t_j, 8/b}
                \draw [ultra thick] (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\xtext$};

            % Adapted
            % f_{i-1}
            \draw [very thick, color=SeaGreen] (0,1) -- (2,1);
            \draw [color=SeaGreen] (1,1.3) node {\( f_{i-1} \)};
            \draw [fill=SeaGreen] (0,1) circle (1.5pt);
            \draw [fill=SeaGreen] (2,1) circle (1.5pt);

            % f_{j-1}
            \draw [very thick, color=SeaGreen] (0,2) -- (2,2);
            \draw [very thick, densely dotted, color=SeaGreen] (2,2) -- (3,2);
            \draw [very thick, color=SeaGreen] (3,2) -- (5,2);
            \draw [color=SeaGreen] (2.5,2.3) node {\( f_{j-1} \)};
            \draw [fill=SeaGreen] (0,2) circle (1.5pt);
            \draw [fill=SeaGreen] (5,2) circle (1.5pt);

            % Instantly independent
            % Ï•_i
            \draw [very thick, color=MidnightBlue] (3,1) -- (5,1);
            \draw [very thick, densely dotted, color=MidnightBlue] (5,1) -- (6,1);
            \draw [very thick, color=MidnightBlue] (6,1) -- (8,1);
            \draw [fill=MidnightBlue] (3,1) circle (1.5pt);
            \draw [fill=MidnightBlue] (8,1) circle (1.5pt);
            \draw [color=MidnightBlue] (5.5,1.3) node {\( Ï•_{i} \)};

            % Ï•_j
            \draw [very thick, color=MidnightBlue] (6,2) -- (8,2);
            \draw [color=MidnightBlue] (7,2.3) node {\( Ï•_{j} \)};
            \draw [fill=MidnightBlue] (6,2) circle (1.5pt);
            \draw [fill=MidnightBlue] (8,2) circle (1.5pt);

            % Setup and bounding box
            % \clip(-2,-1) rectangle (9,3);
            % \draw (current bounding box.north east) rectangle (current bounding box.south west);
        \end{tikzpicture}
        \caption{A \( t \)-dependence plot of the various processes. The dotted regions are removed.}
        \label{fig:isometry_proof}
    \end{figure}

    Putting these together, we see that
    \begin{align}
        & \E\bs{ f_{i-1} Ï•_i f_{j-1} Ï•_j \Del W_i \Del W_j }  \nonumber \\
        & =  \E\bs{ f_{i-1} \br{Ï•(W_b - W_{t_i}) - Ï•(W_b - W_{t_i} - \Del W_j)} f_{j-1} Ï•_j \Del W_i \Del W_j }  \nonumber \\
        & â‰ƒ  \E\bs{ f_{i-1} Î˜ f_{j-1} Ï•_j \Del W_i (\Del W_j)^2 }  \nonumber \\
        & =  \E\bs{ \E\br{ f_{i-1} Î˜ f_{j-1} Ï•_j \Del W_i (\Del W_j)^2 \given â„‹_{t_{j-1}}^{t_j} }}  \nonumber \\
        & =  \E\bs{ f_{i-1} Î˜ f_{j-1} Ï•_j \Del W_i ~ \E\br{\Del W_j}^2}  \nonumber \\
        & =  \E\bs{ f_{i-1} Î˜ f_{j-1} Ï•_j \Del W_i}  \Del t_j . \label{eqn:proof_step_Ï•}
    \end{align}

    We repeat Trick 2 on \( f(W_{t_{j-1}} - \Del W_i) \) just as we did for \( Ï•(W_b - W_{t_i} - \Del W_j) \) to derive \cref{eqn:Ï•_var_0}. This allows us to remove the dependence of \( f_{j-1} \) on \( \bc{W_t: t âˆˆ (t_{i-1}, t_i)} \). This is illustrated in \cref{fig:isometry_proof} by the dotted region of \( f_{j-1} \). Therefore,
    \begin{equation*}
        \E\bs{ f_{i-1} Î˜ f_{j-1} Ï•_j \Del W_i \Del W_j} = 0 ,
    \end{equation*}
    where we used the tower property with respect to the Ïƒ-algebra \( â„‹_{t_{i-1}}^{t_i} \) in this case. As before, we get
    \begin{equation*}
        f(W_{t_{j-1}}) - f(W_{t_{j-1}} - \Del W_i) â‰ƒ f'(W_{t_{j-1}} - \Del W_i) \Del W_i = F \Del W_i ,
    \end{equation*}
    where we write \( F = f'(W_{t_{j-1}} - \Del W_i) \) for brevity.

    Continuing from \cref{eqn:proof_step_Ï•},
    \begin{align}
        & \E\bs{ f_{i-1} ~ Ï•_i ~ f_{j-1} ~ Ï•_j \Del W_i \Del W_j }  \nonumber \\
        & =  \E\bs{ f_{i-1} ~ Î˜ ~ f_{j-1} ~ Ï•_j \Del W_i}  \Del t_j  \nonumber \\
        & =  \E\bs{ f_{i-1} ~ Î˜ \br{f(W_{t_{j-1}}) - f(W_{t_{j-1}} - \Del W_i)} Ï•_j \Del W_i}  \Del t_j  \nonumber \\
        & â‰ƒ  \E\bs{ f_{i-1} ~ Î˜ ~ F ~ Ï•_j (\Del W_i)^2 } \Del t_j  \nonumber \\
        & =  \E\bs{ \E\br{ f_{i-1} ~ Î˜ ~ F Ï•_j (\Del W_i)^2 \given â„‹_{t_{i-1}}^{t_i} }} \Del t_j  \nonumber \\
        & =  \E\bs{ f_{i-1} ~ Î˜ ~ F Ï•_j ~ \E\br{(\Del W_i)^2 \given â„‹_{t_{i-1}}^{t_i} }} \Del t_j  \nonumber \\
        & =  \E\bs{ f_{i-1} ~ Î˜ ~ F Ï•_j } \Del t_i \Del t_j .  \label{eqn:proof-step-f}
    \end{align}

    By the continuity of \( W_t \), we see that as \( \norm{Î _n} â†’ 0 \), so does \( \Del W_i \) and \( \Del W_j \). Moreover, by the continuity of \( f' \) and \( Ï•' \), we can conclude that as \( \norm{Î _n} â†’ 0 \),
    \begin{align*}
        F  & =  f'(W_{t_{i-1}} - \Del W_i)  â†’  f'(W_{t_{j-1}})  =  f_{j-1}' , \text{ and} \\
        Î˜  & =  Ï•'(W_b - W_{t_i} - \Del W_j)  â†’  Ï•'(W_b - W_{t_i}) = Ï•_i' .
    \end{align*}

    Finally, summing \cref{eqn:proof-step-f} over \( i < j \) and taking limit, we get
    \begin{equation*}
        D_1 = âˆ«_a^b âˆ«_a^t \E\bs{ f(W_s) ~ Ï•'(W_b - W_s) ~ f'(W_t) ~ Ï•(W_b - W_t)} \dif s \dif t .
    \end{equation*}
    This concludes the proof.
\end{proof}

One of the features of \cref{thm:isometry_extension_product} is that the result enables us to evaluate the second moment of these anticipating integrals without having to evaluate the integral itself. This is advantageous as explicitly evaluating the integral via the definition can get very complicated. We demonstrate that particular feature with an example.

\begin{example}
    Let \( f(x) = x \) and \( Ï•(y) = y \). Then from \cref{thm:isometry_extension_product},
    \begin{align}
        &  \E\bs{  \br{ âˆ«_a^b W_t ~ (W_b - W_t) \dif W_t }^2 }  \nonumber \\
        & =  âˆ«_a^b \E\bs{ W_t^2 ~ (W_b - W_t)^2 } \dif t
        +  2 âˆ«_a^b âˆ«_a^t \E\bs{ W_s ~ (W_b - W_t) } \dif s \dif t  \nonumber \\
        & =  âˆ«_a^b \E\bs{W_t^2} ~ \E\bs{(W_b - W_t)^2} \dif t
        +  2 âˆ«_a^b âˆ«_a^t \E\bs{W_s} ~ \E\bs{W_b - W_t} \dif s \dif t  \nonumber \\
        & = âˆ«_a^b t(b-t) \dif t  \nonumber \\
        & = \frac16 (b^3 - 3 a^2 b + 2 a^3)  \label{eqn:example_isometry}.
    \end{align}

    Note that this result can also be obtained by explicitly calculating the integral and then taking the expectation of the square. However, this process is extremely tedious and is impractical since we do not always have a closed-form representation of a stochastic integral. We briefly highlight this route mentioning only the key steps.

    Let \( I = âˆ«_a^b W_t ~ (W_b - W_t) \dif W_t \). From \cref{eg:integral_Ws_W_b-W_s}, we get
    \[ I = \frac12 W_b \br{(W_b^2 - W_a^2) - (b - a)} - \frac13 \br{W_b^3 - W_a^3} . \]
    For brevity, we write \( Î”_W = W_b - W_a \), so \( W_b = (W_b - W_a) + W_a = Î”_W + W_a \). Performing algebraic simplification, we get
    \[ I = \frac16 \br{Î”_W^3 + 3 W_a Î”_W^2 - 3 (b - a) Î”_W - 3 (b - a) W_a} . \]
    Note that \( W_a \) and \( Î”_W ~ \) are independent with \( W_a \sim N(0, a) \) and \( Î”_W \sim N(0, (b - a)) \). Therefore, any odd moment of either of \( W_a \) or \( Î”_W \) is zero. Using this, we get
    \begin{align*}
        \E [I^2]
        & =  \frac{1}{36} \
        \E \left[ Î”_W^6 + 9 W_a^2 Î”_W^4 + 9 (b - a)^2 Î”_W^2 + 9 (b - a)^2 W_a^2 \right. \\
        &  \qquad \qquad  \left. - 6 (b - a) Î”_W^4 - 18 (b - a) W_a^2 Î”_W^2 \right]  \\
        & =  \frac16 \br{b^3 - 3 a^2 b + 2 a^3} ,
    \end{align*}
    which is exactly what we obtained in \cref{eqn:example_isometry}.
\end{example}



\section{Identity for a more general case}

We can use the same arguments as those in the proof of \cref{thm:isometry_extension_product} to get the following general theorem.
\begin{theorem}  \label{thm:isometry_extension_general}
    Let \( Î˜(x, y) âˆˆ C^1(â„^2) \) and assume that
    \[ Î˜(W_t, W_b - W_t), ~ Î˜_x(W_t, W_b - W_t), ~ Î˜_y(W_t, W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) . \]
    Then \( \E\br{âˆ«_a^b Î˜(W_t, W_b - W_t) \dif W_t} = 0 \), and
    \begin{align}
        &  \E\bs{ \br{âˆ«_a^b Î˜(W_t, W_b - W_t) \dif W_t}^2}  =  âˆ«_a^b \E\bs{ Î˜(W_t, W_b - W_t)^2} \dif t  \nonumber \\
        &  \quad +  2 âˆ«_a^b âˆ«_a^t \E \Big[ Î˜_y(W_s, W_b - W_s) ~ Î˜_x(W_t, W_b - W_t) \Big] \dif s \dif t . \label{eqn:isometry_extension_general}
    \end{align}
\end{theorem}

We can extend this result to the product of two integrals.\index{isometry!Ayedâ€“Kuo}
\begin{theorem} \label{thm:isometry_extension_inner_product}
    Let \( Î˜(x, y), Î›(x, y) âˆˆ C^1(â„^2) \) and assume that
    \begin{enumerate}
        \item  \( Î˜(W_t, W_b - W_t), ~ Î˜_x(W_t, W_b - W_t), ~ Î˜_y(W_t, W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \), and
        \item  \( Î›(W_t, W_b - W_t), ~ Î›_x(W_t, W_b - W_t), ~ Î›_y(W_t, W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \).
    \end{enumerate}
    Then
    \begin{align}
        &  \E\bs{ \br{âˆ«_a^b Î˜(W_t, W_b - W_t) \dif W_t} \br{âˆ«_a^b Î›(W_t, W_b - W_t) \dif W_t}}  \nonumber \\
        &=  âˆ«_a^b \E\bs{ Î˜(W_t, W_b - W_t) ~ Î›(W_t, W_b - W_t)} \dif t  \nonumber \\
        &  \quad +  âˆ«_a^b âˆ«_a^t \E \Big[
            Î˜_y(W_s, W_b - W_s) ~ Î›_x(W_t, W_b - W_t)  \nonumber \\
        &   \qquad \qquad \qquad  + Î˜_x(W_t, W_b - W_t) ~ Î›_y(W_t, W_b - W_t)
        \Big] \dif s \dif t . \label{eqn:isometry_extension_inner_product}
    \end{align}
\end{theorem}

\begin{proof}
    For this proof, we write \( F(t) = Î˜(W_t, W_b - W_t) \), \( G(t) = Î›(W_t, W_b - W_t) \), and let \( H = F + G \). Moreover, for brevity, we write \( F_x(t) = Î˜_x(W_t, W_b - W_t) \), \( F_y(t) = Î˜_y(W_t, W_b - W_t) \) and corresponding notation for \( G \) and \( H \).

    From the definition of \( H \), we see that
    \begin{align*}
        \E\bs{ \br{âˆ«_a^b H(t) \dif W_t}^2}
        &  = \E\bs{ \br{âˆ«_a^b F(t) \dif W_t + âˆ«_a^b G(t) \dif W_t}^2}  \\
        &  = \E\bs{ \br{âˆ«_a^b F(t) \dif W_t}^2 }
            +  \E\bs{ \br{âˆ«_a^b G(t) \dif W_t}^2 }  \\
        & \qquad  +2 ~ \E\bs{ \br{âˆ«_a^b F(t) \dif W_t} \br{âˆ«_a^b G(t) \dif W_t} } .
    \end{align*}
    Now, applying \cref{thm:isometry_extension_general} for \( F \), we get
    \[ \E\bs{ \br{âˆ«_a^b F(t) \dif W_t}^2}
    =  âˆ«_a^b \E\bs{F(t)^2} \dif t
    +  2 âˆ«_a^b âˆ«_a^t \E\bs{ F_y(s) ~ F_x(t) } \dif s \dif t . \]
    We can obtain an equivalent result for \( G \).
    Putting all this together, we get
    \begin{align}
        \E\bs{ \br{âˆ«_a^b H(t) \dif W_t}^2}
        &  =  âˆ«_a^b \E\bs{F(t)^2} \dif t
            +2 âˆ«_a^b âˆ«_a^t \E\bs{ F_y(s) ~ F_x(t) } \dif s \dif t  \nonumber \\
        &  \quad + âˆ«_a^b \E\bs{G(t)^2} \dif t
            +  2 âˆ«_a^b âˆ«_a^t \E\bs{ G_y(s) ~ G_x(t) } \dif s \dif t  \nonumber \\
        &  \quad +2 ~ \E\bs{ \br{âˆ«_a^b F(t) \dif W_t} \br{âˆ«_a^b G(t) \dif W_t} } . \label{eqn:product-definition-theorem}
    \end{align}

    On the other hand, first applying \cref{thm:isometry_extension_general} and then using the definition of \( H \), we get
    \begin{align}
        &  \E\bs{ \br{âˆ«_a^b H(t) \dif W_t}^2}  \nonumber \\
        &  = âˆ«_a^b \E\bs{H(t)^2} \dif t
            +  2 âˆ«_a^b âˆ«_a^t \E\bs{H_y(s) ~ H_x(t)} \dif s \dif t  \nonumber \\
        &  =   âˆ«_a^b \E\bs{F(t)^2} \dif t
            +  âˆ«_a^b \E\bs{G(t)^2} \dif t
            +2 âˆ«_a^b \E\bs{F(t) G(t)} \dif t  \nonumber \\
        & \quad +  2 âˆ«_a^b âˆ«_a^t \E\bs{(F_y(s) + G_y(s)) (F_x(t) + G_x(t))} \dif s \dif t  \nonumber \\
        &  =   âˆ«_a^b \E\bs{F(t)^2} \dif t
            +  âˆ«_a^b \E\bs{G(t)^2} \dif t
            +2 âˆ«_a^b \E\bs{F(t) G(t)} \dif t  \nonumber \\
        & \quad +  2 âˆ«_a^b âˆ«_a^t \E \Big[ F_y(s) F_x(t) + F_y(s) G_x(t) + G_y(s) F_x(t) + G_y(s) G_x(t) \Big] \dif s \dif t . \label{eqn:product-theorem-definition}
    \end{align}

    Finally, \cref{eqn:product-definition-theorem} and \cref{eqn:product-theorem-definition} imply that
    \begin{align*}
        &  \E\bs{ \br{âˆ«_a^b F(t) \dif W_t} \br{âˆ«_a^b G(t) \dif W_t}}  \\
        &  =  âˆ«_a^b \E\bs{ F(t) ~ G(t)} \dif t
            +  âˆ«_a^b âˆ«_a^t \E\bs{F_y(s) ~ G_x(t) + G_y(s) ~ F_x(t)} \dif s \dif t ,
    \end{align*}
    which is exactly the desired result.
\end{proof}

If \( Î˜(x, y) = f(x) \) and \( Î›(x, y) = Ï•(y) \), we have \( Î˜_y \equiv 0 \) and \( Î›_x \equiv 0 \). Therefore, we obtain the following corollary.
\begin{corollary}  \label{cor:isometry_extension_inner_product}
Let \( f, Ï• âˆˆ C^1(â„) \) and assume that
    \begin{enumerate}
        \item  \(  f(W_t),  Ï•(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \), and
        \item  \( f'(W_t), Ï•'(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \).
    \end{enumerate}
    Then
    \begin{align*}
        &\E\bs{\br{âˆ«_a^b  f(W_t) \dif W_t} \br{âˆ«_a^b Ï•(W_b - W_t) \dif W_t}}  \\
        & =   âˆ«_a^b \E\bs{ f(W_t) ~ Ï•(W_b - W_t) } \dif t
        +  âˆ«_a^b âˆ«_a^t \E\bs{Ï•'(W_b - W_s) ~ f'(W_t)} \dif s \dif t .
    \end{align*}
\end{corollary}

Similar to \cref{thm:isometry_extension_product}, Corollary \cref{cor:isometry_extension_inner_product} enables us to evaluate the covariance between anticipating and adapted integrals without explicitly calculating the integral itself. This is illustrated in the following example.
\begin{example}
    Let \( f(x) = x \) and \( Ï•(y) = y \). Using Corollary \cref{cor:isometry_extension_inner_product}, we get
    \begin{align*}
        &  \E\bs{\br{âˆ«_a^b W_t \dif W_t} \br{âˆ«_a^b (W_b - W_t) \dif W_t}}  \nonumber \\
        &=  âˆ«_a^b \E\br{W_t ~ (W_b - W_t)} \dif t
        +  âˆ«_a^b âˆ«_a^t \E\br{1} \dif s \dif t  \nonumber \\
        &=  âˆ«_a^b \E\br{W_t} \E\br{W_b - W_t} \dif t
        +  âˆ«_a^b (t - a) \dif t \nonumber \\
        &=  \frac12 (b - a)^2 .
    \end{align*}
\end{example}

% A particular case of the above is the case for a process which is the sum of an adapted process and an instantly-independent process.
% \begin{corollary}  \label{cor:isometry_extension_sum}
%     Let \( f, Ï• âˆˆ C^1(â„) \) such that
%     \begin{enumerate}
%         \item  \( f(W_t), Ï•(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \), and
%         \item  \( f'(W_t), Ï•'(W_b - W_t) âˆˆ L^2([a, b] Ã— Î©) \).
%     \end{enumerate}
%     Then
%     \begin{align}
%         &  \E\bs{ \br{ âˆ«_a^b \br{ f(W_t) + Ï•(W_b - W_t) } d W_t }^2}  \nonumber \\
%         &  =  âˆ«_a^b \E\bs{f(W_t)^2} \dif t
%         +  âˆ«_a^b \E\bs{Ï•(W_b - W_t)^2} \dif t   \nonumber \\
%         &  \quad + 2  âˆ«_a^b \E\bs{f(W_t)} \E\bs{Ï•(W_b - W_t)} \dif t  \nonumber \\
%         &  \quad + 2  âˆ«_a^b âˆ«_a^t \E\bs{ Ï•'(W_b - W_s) f'(W_t) } \dif s \dif t .  \label{eqn:isometry_extension_sum}
%     \end{align}
% \end{corollary}

% \begin{proof}
%     Use \( Î˜(x, y) = f(x) Ï•(y) \) in \cref{eqn:isometry_extension_general}.
% \end{proof}

% As an example, we use Corollary \cref{cor:isometry_extension_sum} in calculating the second moment of the anticipatory integral in example \cref{example:antipatoryint}. Namely,

% \begin{example} \label{example:secondmoment}
% \begin{align*}
%     \E  \left[ \br{ âˆ«_a^b W_b \dif W_t }^2\right]  =& \E  \left[\br{ âˆ«_a^b W_t + (W_b - W_t)  \dif W_t }^2\right] \\
%     = & âˆ«_a^b \E \left[ W_t ^2 \right] \dif t + âˆ«_a^b \E \left[\br{  W_b - W_t }^2 \right] \dif t  \\
%     & +    âˆ«_a^b \E \left[W_t\right] \E \left[W_b - W_t\right] \dif t + 2 âˆ«_a^b âˆ«_a^t \E [1] \dif s \dif t \\
%     =& âˆ«_a^b t ~ dt +  âˆ«_a^b (b - t) \dif t + 2 âˆ«_a^b (t-a) \dif t \\
%     =& ~b( b - a) + ( b - a )^2 \\
%     =& ~  (2b-a) (b - a)
% \end{align*}

% \end{example}
% \begin{example}
%     Let \( Î˜(x, y) = e^x + \sin(y) \). Then by Corollary \cref{cor:isometry_extension_sum}, we have
%     \begin{align*}
%         &  \E\bs{  \br{ âˆ«_a^b \br{e^{W_t} + \sin(W_b - W_t)} \dif W_t }^2 }  \\
%         &  =  âˆ«_a^b \E\bs{e^{2 W_t}} \dif t
%         +  âˆ«_a^b \E\bs{\sin^2(W_b - W_t)} \dif t   \nonumber \\
%         &  \quad + 2  âˆ«_a^b \E\bs{e^{W_t}} \E\bs{\sin(W_b - W_t)} \dif t  \nonumber \\
%         &  \quad + 2  âˆ«_a^b âˆ«_a^t \E\bs{ e^{W_t} \cos(W_b - W_s) } \dif s \dif t .
%     \end{align*}
% \end{example}

% We give a simple example of a function for which we need the most general result \cref{eqn:isometry_extension_general}.

% \begin{example}
%     Let \( Î˜(x, y) = \sin(xy) \). Then \( \frac{\partial Î˜}{\partial x} = y \cos(xy) \) and \( \frac{\partial Î˜}{\partial y} = x \cos(xy) \). Therefore,
%     \begin{align*}
%         &  \E\bs{ \br{âˆ«_a^b \sin(W_t (W_b - W_t)) \dif W_t}^2 }
%         =  âˆ«_a^b \E\bs{ \sin(W_t (W_b - W_t))^2 } \dif t  \\
%         &  \quad +  2 âˆ«_a^b âˆ«_a^t \E \left[ W_s \cos(W_s (W_b - W_s)) (W_b - W_t) \cos(W_t (W_b - W_t)) \right] \dif s \dif t .
%     \end{align*}
% \end{example}

% \begin{example}
%     Let \( Î˜(x, y) = e^{xy} \). Then \( Î˜_x = y e^{xy} \) and \( Î˜_y = x e^{xy} \). Therefore,
%     \begin{align*}
%         &  \E\bs{ \br{âˆ«_a^b e^{W_t (W_b - W_t)} \dif W_t}^2 }
%         =  âˆ«_a^b \E\bs{ e^{2W_t (W_b - W_t)} } \dif t  \\
%         &  \quad +  2 âˆ«_a^b âˆ«_a^t \E \left[ W_s e^{W_s (W_b - W_s)} (W_b - W_t) e^{W_t (W_b - W_t)} \right] \dif s \dif t .
%     \end{align*}
% \end{example}


Finally, we want to point our that the double integral in \cref{eqn:isometry_extension_general} can be regarded as a correction term when we extend ItÃ´'s theory to anticipating stochastic integration. This correction term can be positive or negative, as illustrated in the next example.

\begin{example}
    Consider the case \( Î˜(x,y) = px + y \) in \cref{thm:isometry_extension_general}, where \( p âˆˆ â„ \). Then \( Î˜_x = p \) and \( Î˜_y = 1 \). Therefore, we can directly evaluate the double integral in \cref{eqn:isometry_extension_general} as
    \[ 2 âˆ«_a^b âˆ«_a^t \E\bs{Î˜_y(W_s, W_b - W_s) ~ Î˜_x(W_t, W_b - W_t)} \dif s \dif t  =  2 âˆ«_a^b âˆ«_a^t p \dif s \dif t  =  p (b - a)^2 . \]
    Therefore, the final term will be positive or negative depending on the sign of \( p \).
\end{example}
