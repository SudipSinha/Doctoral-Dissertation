% !TeX root = ../dissertation.tex

\section{Motivation}
\footnotetextonly{Parts of this chapter previously appeared in the following open-access article: \fullcite{KuoShresthaSinhaSundar2022}.}

We now come to a central motivation behind the definition of the Ayed‚ÄìKuo integral --- martingales. Recall that a martingale \( M \) is an integrable adapted process such that \( \E\br{M_t \given ‚Ñ±_s} = M_s \) almost surely for every \( s ‚â§ t \) (see \cref{sec:martingales}). Moreover, the process \( M_t = ‚à´_a^t X_s \dif W_s \) generated by the It√¥'s integral of an adapted process \( X_s \) is a martingale. Can we say the same about processes associated with Ayed‚ÄìKuo integrals?

\begin{example}  \label{eg:integral_Wb_t_linearity}
    Consider the process \( N(t) = ‚à´_a^t W_b \dif W_t \). Using the linearity of the integral and \cref{eg:integral_Wb}, we can write
    \begin{align*}
        N(t)
        & =  ‚à´_a^t W_b \dif W_s  \\
        & =  ‚à´_a^b W_b \dif W_s - ‚à´_t^b W_b \dif W_s  \\
        & =  [W_b (W_b - W_a) - (b - a)] - [W_b (W_b - W_t) - (b - t)]  \\
        & =  W_b (W_t - W_a) - (t - a) .
    \end{align*}
    We write \( W_b = (W_b - W_t) + (W_t - W_s) + W_s \) and \( W_t - W_a = (W_t - W_s) + (W_s - W_a) \). Using the independence of increments of Wiener process, we get
    \begin{equation*}
        \E\br{N(t) \given ‚Ñ±_s}  =  W_s (W_s - W_a) - (s - a)  ‚â†  N(s) .
    \end{equation*}
    So the process \( N \) is not a martingale. However, note that \( \E\br{N(s) \given ‚Ñ±_s} = W_s (W_s - W_a) - (s - a) = \E\br{N(t) \given ‚Ñ±_s} \), or equivalently, \( \E\br{N(t) - N(s) \given ‚Ñ±_s} = 0 \).
\end{example}

The above example motivates the following definition.
\begin{definition}[{\cite[definition 2.1]{HwangKuoSait√¥Zhai2017}}]  \index{near-martingale}  \index{near-submartingale}  \index{near-supermartingale}
    An integrable stochastic process \( N \) is called a \emph{near-martingale} if \( \E\br{N(t) - N(s) \given ‚Ñ±_s} = 0 \) almost surely for every \( s ‚â§ t \). It is called a \emph{near-submartingale} if we replace the second condition with \( \E\br{N(t) - N(s) \given ‚Ñ±_s} ‚â• 0 \), and is called a \emph{near-supermartingale} when \( \E\br{N(t) - N(s) \given ‚Ñ±_s} ‚â§ 0 \).
\end{definition}
Clearly, a process that is both a near-submartingale and a near-supermartingale is a near-martingale. Moreover, any result that is true for a near-submartingale can be suitably modified for a near-supermartingale, and subsequently for a near-martingale. Therefore, in what follows, we only show results for submartingales.

For any near-submartingale \( N \), we will called the process \( M_t = \E\br{N(t) \given ‚Ñ±_t} \) as the \emph{conditioned process}\index{conditioned process}.

It is evident from the definition that every submartingale is a near-submartingale. More generally, a near-submartingale and its conditioned process are related by the following fundamental result.
\begin{proposition}[{\cite[theorem 2.5]{HwangKuoSait√¥Zhai2017}}]  \label{thm:near-martingale_martingale}
    A process \( N \) is a near-submartingale if and only if the conditioned process \( M \) given by \( M_t = \E\br{N(t) \given ‚Ñ±_t} \) is a submartingale.
\end{proposition}
\begin{proof}
    Note that the integrability condition is trivially satisfied. We prove the result for the \emph{sub}-case. The other cases can be similarly derived. In what follows, we assume \( s ‚â§ t \) and hence \( ‚Ñ±_s ‚äÜ ‚Ñ±_t \).

    For one direction, assume that \( N \) is a near-submartingale. Then
    \begin{equation*}
        \E\br{M_t \given ‚Ñ±_s}
        =  \E\br{\E\br{N(t) \given ‚Ñ±_t} \given ‚Ñ±_s}
        =  \E\br{N(t) \given ‚Ñ±_s}
        ‚â•  \E\br{N(s) \given ‚Ñ±_s}
        =  M_s ,
    \end{equation*}
    so \( M \) is a submartingale.

    For the other direction, assume \( M \) is a submartingale. Then
    \begin{equation*}
        \E\br{N(t) \given ‚Ñ±_s}
        =  \E\br{\E\br{N(t) \given ‚Ñ±_t} \given ‚Ñ±_s}
        =  \E\br{M_t \given ‚Ñ±_s}
        ‚â•  M_s
        =  \E\br{N(s) \given ‚Ñ±_s} ,
    \end{equation*}
    so \( N \) is a near-submartingale.
\end{proof}



\section{Ayed‚ÄìKuo integrals are near-martingales}  \label{sec:Ayed‚ÄìKuo_near-martingale}

The following theorem shows that Ayed‚ÄìKuo integrals are near-martingales.

\begin{theorem}[{\cite[theorem 3.3]{KuoShresthaSinhaSundar2022}}]  \label{thm:Ayed‚ÄìKuo_integral_near-martingale}
    Suppose \( Œò \) is a real-valued measurable function on \( ‚Ñù^2 \). Assume \( L^2(Œ©) \)-convergence for the Ayed‚ÄìKuo integral. Then \( N(t) = ‚à´_a^t Œò(W_u, W_b - W_u) \dif W_u \) is a near-martingale.
\end{theorem}
\begin{proof}
    The definition of the Ayed‚ÄìKuo integral under \( L^2(Œ©) \)-limits implies that for any \( s ‚â§ t \),
    \begin{align*}
        \E\bs{N(t) - N(s) \given ‚Ñ±_s}
        & =  \E\bs{‚à´_s^t Œò(W_u, W_b - W_u) \dif W_u \given ‚Ñ±_s}  \\
        & =  \E\bs{\lim_{n ‚Üí ‚àû} ‚àë_{i = 1}^‚àû Œò(W_{t_{i-1}}, W_b - W_{t_i}) \Del W_i \given ‚Ñ±_s}  \\
        & =  \lim_{n ‚Üí ‚àû} ‚àë_{i = 1}^‚àû \E\bs{Œò(W_{t_{i-1}}, W_b - W_{t_i}) \Del W_i \given ‚Ñ±_s} .
    \end{align*}

    \begin{figure}[ht]
        \centering
        \begin{tikzpicture}
        \centering
            %  Background squares

            % ‚Ñã_{t_{i-1}}^{t_i}
            \fill [Brown!12.5] (0,0) rectangle (3,2);
            \fill [Brown!12.5] (5,0) rectangle (8,2);
            \node (separation) at (4, 2.75) [Brown] {\( ‚Ñã_{t_{i-1}}^{t_i} \)};
            \draw [->, thick, color=Brown] (separation.west) to [bend right=10] (1.5,1.75);
            \draw [->, thick, color=Brown] (separation.east) to [bend left=10 ] (5.5,1.75);
            
            % ‚Ñ±_s
            \node (separation) at (0, 2.5) [ForestGreen] {\( ‚Ñ±_s \)};
            \draw [-latex, thick, color=ForestGreen] (separation.east) to [bend left=10] (0.5,1.75);
            \fill [pattern=north west lines, pattern color=ForestGreen] (0,0) rectangle (1,2);

            % Main timeline
            \draw [->, very thick, color=gray] (-2,0) -- (9,0) node[below] {\( t \)};
            \foreach \x/\xtext in {-1/0, 0/a, 1/s, 3/t_{i-1}, 5/t_i, 7/t, 8/b}
                \draw [ultra thick] (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\xtext$};

            % Left process
            \draw [very thick, color=Brown] (0,0.75) -- (3,0.75);
            \draw [color=Brown] (2,1.1) node {\( W_{t_{i-1}} \)};
            \draw [fill=Brown] (0,0.75) circle (1.5pt);
            \draw [fill=Brown] (3,0.75) circle (1.5pt);

            % Right process
            \draw [very thick, color=Brown] (5,0.75) -- (8,0.75);
            \draw [color=Brown] (6.5,1) node {\( W_1 - W_{t_i} \)};
            \draw [fill=Brown] (5,0.75) circle (1.5pt);
            \draw [fill=Brown] (8,0.75) circle (1.5pt);

            % Center process
            \draw [very thick, color=SteelBlue] (3,1.25) -- (5,1.25);
            \draw [color=SteelBlue] (4,1.6) node {\( W_{t_i} - W_{t_{i-1}} \)};
            \draw [fill=SteelBlue] (3,1.25) circle (1.5pt);
            \draw [fill=SteelBlue] (5,1.25) circle (1.5pt);

            % Setup and bounding box
            % \clip(-2,-1) rectangle (9,3);
            % \draw (current bounding box.north east) rectangle (current bounding box.south west);
        \end{tikzpicture}
        \caption{Inclusion of œÉ-algebras along with disjoint increments of \( W \).}
        \label{fig:œÉ-algebra_inclusion}
    \end{figure}

    Using the tower property of conditional expectation (\cref{thm:conditional_expectation_properties}) and the inclusion \( ‚Ñã_{t_{i-1}}^{t_i} ‚äá ‚Ñ±_s \) (see \cref{fig:œÉ-algebra_inclusion}), we get
    \begin{equation*}
        \E\bs{ Œò(W_{t_{i-1}}, W_b - W_{t_i}) \Del W_i \given ‚Ñ±_s }
        =  \E\bs{ \E\br{ Œò(W_{t_{i-1}}, W_b - W_{t_i}) \Del W_i \given ‚Ñã_{t_{i-1}}^{t_i} } \given ‚Ñ±_s } .
    \end{equation*}
    Since \( Œò(W_{t_{i-1}}, W_b - W_{t_i}) \) is \( ‚Ñã_{t_{i-1}}^{t_i} \)-measurable and \( \Del W_i \) is independent to \( ‚Ñã_{t_{i-1}}^{t_i} \), we get
    \begin{equation*}
        \E\bs{ Œò(W_{t_{i-1}}, W_b - W_{t_i}) \Del W_i \given ‚Ñ±_s }
        =  \E\bs{Œò(W_{t_{i-1}}, W_b - W_{t_i}) \cancelto{0}{\E\br{\Del W_i}} \given ‚Ñ±_s }
        =  0 .
    \end{equation*}
    By the continuity of limits, we get our desired result \( \E\bs{N(t) - N(s) \given ‚Ñ±_s} = 0 \).
\end{proof}

\begin{remark}
    Note that the above proof also implies \( \E\bs{N(t) - N(s) \given G^t} = 0 \) for any \( s ‚â§ t \). This shows that Ayed‚ÄìKuo integrals are also \emph{backward near-martingales}\index{near-martingale!backward}. Similarly, the process \( \widetilde{N}(t) = ‚à´_t^b Œò(W_u, W_b - W_u) \dif W_u \) is a near-martingale and a backward near-martingales by the same logic.
\end{remark}

Let us look at an example of the above proposition.
\begin{example}[{\cite[example 2.7]{HwangKuoSait√¥2019}}]
    In \cref{eg:integral_Ws_W_b-W_s}, we showed that
    \begin{equation*}
        Z(t) = ‚à´_a^t W_s (W_b - W_s) \dif W_s  =  \frac12 W_b \br{(W_t^2 - W_a^2) - (t - a)} - \frac13 \br{W_t^3 - W_a^3} .
    \end{equation*}
    From \cref{thm:Ayed‚ÄìKuo_integral_near-martingale}, we conclude that \( Z(t) \) is a near-martingale. On the other hand, we can verify this using the conditional expectation \( M_t = \E\br{Z(t) \given ‚Ñ±_t} \) and \cref{thm:near-martingale_martingale}. Now,
    \begin{align*}
        M_t
        & =  \E\br{Z(t) \given ‚Ñ±_t}  \\
        & =  \frac12 \E\br{W_b \given ‚Ñ±_t} \br{(W_t^2 - W_a^2) - (t - a)} - \frac13 \br{W_t^3 - W_a^3}  \\
        & =  \frac12 W_t \br{(W_t^2 - W_a^2) - (t - a)} - \frac13 \br{W_t^3 - W_a^3}  \\
        & =  \frac16 \br{(W_t^3 - 3 t W_t) - 3 (W_a^2 - a) W_t + 2 W_a^2} .
    \end{align*}
    We can easily check that \( W_t \) and \( W_t^3 - 3 t W_t \) are martingales. Therefore \( M \) is also a martingale, as expected.
\end{example}

The product of a martingale and an instantly-independent process is a near-martingale if and only if the instantly-independent process has constant mean.
\begin{proposition}[{\cite[theorem 2.9]{HwangKuoSait√¥2019}}]  \label{thm:martingale_instantlyindependent_product}
    Suppose \( M \) is a submartingale and \( Y \) an instantly-independent process such that both \( M_t \) and \( Y^t \) are square-integrable for each \( t \). Then the process \( N \) given by \( N(t) = M_t Y^t \) is a near-submartingale if and only if \( \E\br{Y^t} \) is a constant.
\end{proposition}
\begin{proof}
    Note that
    \begin{equation*}
        \E\br{N(t) \given ‚Ñ±_t}
        =  \E\br{M_t Y^t \given ‚Ñ±_t}
        =  M_t \E\br{Y^t \given ‚Ñ±_t}
        =  M_t \E\br{Y^t} .
    \end{equation*}
    Therefore, \( \E\br{N(t) \given ‚Ñ±_t} \) is a submartingale if and only if \( \E\br{Y^t} \) is a constant. By \cref{thm:near-martingale_martingale}, \( N(t) \) is a near-submartingale if and only if \( \E\br{Y^t} \) is a constant.
\end{proof}



\section{Stopped near-martingales}

In this section, we show that stopped near-martingales are near-martingales. Moreover, we give a optional stopping theorem for near-martingales on the lines of Doob's optional stopping theorem (\cref{thm:optional_stopping_Doob}).

\begin{definition}  \label{def:near-martingale_transform}
    Let \( \br{A_n}_{n = 0}^‚àû \) be an adapted process and \( \br{X_n}_{n = 0}^‚àû \) a discrete time near-submartingale. Then the processes \( \br{Y_n}_{n = 0}^‚àû \), where \( Y_0 = 0 \) and
    \begin{equation*}
        Y_n = (A ‚àô X)_n = ‚àë_{i = 1}^n A_{n-1} (X_n - X_{n-1})
    \end{equation*}
    is called the \emph{near-martingale transform}\index{near-martingale transform} of \( X \) by \( A \).
\end{definition}

Near-martingale transforms retain the near-martingale property. This is a generalization \cref{thm:martingale_transform} to near-martingales.
\begin{proposition}  \label{thm:near-martingale_transform}
    \begin{enumerate}
        \item \label{itm:near-martingale_transform_bounded_positive}  If \( X \) is a near-submartingale and \( A \) is a bounded non-negative adapted process, then \( (A ‚àô X) \) is a near-submartingale.
        \item \label{itm:near-martingale_transform_bounded} If \( X \) is a near-martingale and \( A \) is a bounded adapted process, then \( (A ‚àô X) \) is a near-martingale.
        \item  If \( X \) and \( A \) are both square integrable, then we do not require the boundedness condition in \cref{itm:near-martingale_transform_bounded_positive,itm:near-martingale_transform_bounded}.
    \end{enumerate}
\end{proposition}
\begin{proof}
    We only prove \cref{itm:near-martingale_transform_bounded_positive} because the rest follow the same process. Let \( X \) be a near-submartingale and \( Y = (A ‚àô X) \). Suppose \( n \) is an arbitrary time. Note that \( Y_n - Y_{n-1} = A_{n-1} (X_n - X_{n-1}) \), which is integrable since \( A \) is bounded. Using the adaptedness of \( A \), we get
    \begin{equation*}
        \E\br{Y_n - Y_{n-1} \given ‚Ñ±_{n-1}}
        =  \E\br{A_{n-1} (X_n - X_{n-1}) \given ‚Ñ±_{n-1}}
        =  A_{n-1} \E\br{X_n - X_{n-1} \given ‚Ñ±_{n-1}}
        ‚â•  0 ,
    \end{equation*}
    where the last inequality holds since \( A \) is non-negative.
\end{proof}

The following result says that stopped near-submartingales are near-submartingales.
\begin{theorem}  \label{thm:near-martingale_stopped}
    Suppose \( X \) is a discrete time near-submartingale and \( œÑ \) a stopping time. Then the stopped process \( X^œÑ \) defined by \( X^œÑ_n = X_{œÑ ‚àß n} \) is a (discrete time) near-submartingale.
\end{theorem}
\begin{proof}
    Let \( A_n = ùüô_{\bc{n ‚â§ œÑ}} \). Clearly, the process \( A \) is bounded, non-negative, and adapted. Now, note that \( X^œÑ_n - X_0 = X_{œÑ ‚àß n} - X_0 = (A ‚àô X)_n \). Therefore, by \cref{thm:near-martingale_transform}, we get that \( X^œÑ \) is a near-submartingale.
\end{proof}



Now, we show the equivalent result of Doob's optional stopping theorem (\cref{thm:optional_stopping_Doob}) for discrete time near-submartingales\index{optional stopping theorem!near-martingale}.
\begin{theorem}  \label{thm:optional_stopping_near-martingale_discrete_time}
    Let \( X \) be a discrete time near-submartingale. Suppose \( œÉ \) and \( œÑ \) are two bounded stopping times with \( œÉ ‚â§ œÑ \). Then \( X_œÉ \) and \( X_œÑ \) are integrable, and \( \E\br{X_œÑ - X_œÉ \given ‚Ñ±_œÉ} ‚â• 0 \) almost surely.
\end{theorem}
\begin{proof}
    Since \( œÉ \) and \( œÑ \) are bounded, there exists \( N < ‚àû \) such that \( œÉ ‚â§ œÑ ‚â§ N \). Let \( Y \) be any near-submartingale. Clearly, \( Y_œÉ \) is integrable. Suppose \( E ‚àà ‚Ñ±_œÉ \). Then for any \( n ‚â§ N \), we have \( E ‚à© \bc{œÉ = n} ‚àà ‚Ñ±_n \), and so
    \[ ‚à´_{E ‚à© \bc{œÉ = n}} \br{Y_N - Y_œÉ} \dif \Pr  ~ =  ‚à´_{E ‚à© \bc{œÉ = n}} \br{Y_N - Y_n} \dif \Pr  ~ ‚â•  0 . \]
    Summing over \( n \), we get \( ‚à´_E \br{Y_N - Y_œÉ} \dif \Pr ‚â• 0 \), and so \( \E\br{Y_N - Y_œÉ \given ‚Ñ±_œÉ} ‚â• 0 \). Finally, let \( Y_n = X^œÑ_n \) to get
    \[ \E\br{X^œÑ_N - X^œÑ_œÉ \given ‚Ñ±_œÉ}  =  \E\br{X_œÑ - X_œÉ \given ‚Ñ±_œÉ}  ‚â•  0 . \]
\end{proof}

We need the following definition and lemma to prove the result in continuous time.
\begin{definition}
    Let \( \br{‚Ñ±_n}_{n = 1}^‚àû \) be a decreasing sequence of œÉ-algebras, and let \( X = \br{X_n}_{n = 1}^‚àû \) be a stochastic process. Then the pair \( \br{X_n, ‚Ñ±_n}_{n = 1}^‚àû \) is called a \emph{backward near-submartingale} if for every \( n \),
    \begin{enumerate}
        \item  \( X_n \) is integrable and \( ‚Ñ±_n \)-measurable, and
        \item  \( \E\br{X_n - X_{n+1} \given ‚Ñ±_{n+1}} ‚â• 0 \).
    \end{enumerate}
\end{definition}

\begin{lemma}  \label{thm:backward_near-submartingale_UI}
    Let \( \br{X_n, ‚Ñ±_n}_{n = 1}^‚àû \) be a backward near-submartingale with \( \E\br{X_n} > -‚àû \). If \( X \) is non-negative for every \( n \), then \( X \) is uniformly integrable.
\end{lemma}
\begin{proof}
    As \( n ‚Üó ‚àû \), we have \( \E\br{X_n} ‚Üò \lim_{n ‚Üí ‚àû} \E\br{X_n} = \inf_n \E\br{X_n} > -‚àû \). Fix \( œµ > 0 \). By the definition of infimum, there exists a \( N > 0 \) such that for any \( n ‚â• N \), we have \( \E\br{X_N} - \lim_{n ‚Üí ‚àû} \E\br{X_n} < œµ \).

    For any \( k ‚â• n \) and \( Œ¥ > 0 \), we have
    \begin{equation*}
        \E\br{\abs{X_k} ùüô_{\bc{\abs{X_k} > Œ¥}}}
        =  \E\br{X_k ùüô_{\bc{X_k > Œ¥}}} + \E\br{ X_k ùüô_{\bc{X_k ‚â• -Œ¥}}} - \E\br{X_k} .
    \end{equation*}
    Moreover, since \( X \) is a backward near-submartingale, \( \E\br{X_k ùüô_{\bc{X_k ‚â• Œ¥}}} ‚â§ \E\br{X_n ùüô_{\bc{X_k ‚â• Œ¥}}} \). Therefore,
    \begin{align*}
        \E\br{\abs{X_k} ùüô_{\bc{\abs{X_k} > Œ¥}}}
        & ‚â§  \E\br{X_n ùüô_{\bc{X_k > Œ¥}}} + \E\br{X_n ùüô_{\bc{X_k ‚â• -Œ¥}}} - \br{\E\br{X_n} - œµ}  \\
        & ‚â§  \E\br{\abs{X_n} ùüô_{\bc{\abs{X_k} > Œ¥}}} + œµ .
    \end{align*}
    By Markov's inequality and the non-negativity of \( X \),
    \begin{equation*}
        \Pr\bc{\abs{X_k} > Œ¥}
        ‚â§  \frac1Œ¥ \E\abs{X_k}
        =  \frac1Œ¥ \E\br{X_k}
        ‚â§  \frac1Œ¥ \E\br{X_0}
        ‚Üí 0
    \end{equation*}
    as \( Œ¥ ‚Üí ‚àû \). This concludes the proof.
\end{proof}

We are now ready to prove the near-martingale optional stopping theorem in continuous time.
\begin{theorem}  \label{thm:optional_stopping_near-martingale_continuous}
    Let \( N \) be a near-submartingale with right-continuous sample paths. Suppose \( œÉ \) and \( œÑ \) are two bounded stopping times with \( œÉ ‚â§ œÑ \). If \( N \) is non-negative or uniformly integrable, then \( N(œÉ) \) and \( N(œÑ) \) are integrable, and \[ \E\br{N(œÑ) - N(œÉ) \given ‚Ñ±_œÉ} ‚â• 0  \text{ almost surely.} \]
\end{theorem}
\begin{proof}
    We use a discretization argument to prove the result. Let \( T > 0 \) be a bound for \( œÑ \). For every \( n ‚àà ‚Ñï \), define the discretization function
    \begin{equation}
        f_n: [0, ‚àû) ‚Üí \bc{\frac{k}{n} : k = 0, \dotsc, n}: x ‚Ü¶ \frac{\floor{2^n x} + 1}{2^n} ‚àß T ,
    \end{equation}
    and let \( œÉ_n = f_n(œÉ) \) and \( œÑ_n = f_n(œÑ) \).
    
    Now, for any \( n \) and \( t \),
    \begin{equation*}
        \bc{œÑ_n ‚â§ t}
        =  \bc{f_n(œÑ) ‚àà [0, t]}
        =  \bc{œÑ ‚àà f_n^{-1}[0, t]}
        =  \bc{œÑ ‚àà f_n^{-1} \bs{0, {\frac{\floor{2^n t}}{2^n}}}}
        ‚àà  ‚Ñ±_{\frac{\floor{2^n t}}{2^n}} ‚äÜ ‚Ñ±_t ,
    \end{equation*}
    so \( œÑ_n \) is a stopping time. Similarly, \( œÉ_n \) is a stopping time. Moreover, it can be easily seen that \( œÉ_n ‚â§ œÑ_n \) for every \( n \), and \( œÉ_n ‚Üò œÉ \) and \( œÑ_n ‚Üò œÑ \) as \( n ‚Üó ‚àû \). Therefore, by the discrete time near-submartingale optional stopping theorem \cref{thm:optional_stopping_near-martingale_discrete_time}, we get \( N(œÉ_n) \) and \( N(œÑ_n) \) are integrable, and \( \E\br{N(œÑ_n) - N(œÉ_n) \given ‚Ñ±_{œÉ_n}} ‚â• 0 \) almost surely. Furthermore, it is easy to see that \( ‚Ñ±_œÉ = ‚ãÇ_{n = 1}^‚àû ‚Ñ±_{œÉ_n} ‚äÜ ‚Ñ±_{œÉ_n} \) for any \( n \). Therefore, \( \E\br{N(œÑ_n) - N(œÉ_n) \given ‚Ñ±_œÉ} ‚â• 0 \) almost surely.

    If \( N \) is non-negative, by construction, \( \br{N_{œÉ_n}, ‚Ñ±_{œÉ_n}}_{n = 1}^‚àû \) is a backward near-submartingale such that \( N_{œÉ_n} ‚â• 0 \) for every \( n \). Therefore, \( \E\br{N(œÉ_n)} ‚Üò \E\br{N(œÉ)} > -‚àû \) as \( n ‚Üó ‚àû \). Using \cref{thm:backward_near-submartingale_UI}, \( \br{N(œÉ_n)}_{n = 1}^‚àû \) is uniformly integrable. Similarly, \( \br{N(œÑ_n)}_{n = 1}^‚àû \) is also uniformly integrable. On the other hand, if \( N \) is uniformly integrable, this is trivial.

    Using the right continuity of \( N \) and the boundedness assumption of \( œÉ \) and \( œÑ \), we get \( \lim_{n ‚Üí ‚àû} N(œÉ_n) = N(œÉ) \) and \( \lim_{n ‚Üí ‚àû} N(œÑ_n) = N(œÑ) \) almost surely. Furthermore, the uniform integrability of \( \br{N(œÉ_n)}_{n = 1}^‚àû \) and \( \br{N(œÑ_n)}_{n = 1}^‚àû \) allows us to conclude that \( N(œÉ) \) and \( N(œÑ) \) are integrable and that the convergence is also in \( L^1 \), giving us \( \E\br{N(œÑ) - N(œÉ) \given ‚Ñ±_œÉ} ‚â• 0 \) almost surely.
\end{proof}

We highlight the special case of \cref{thm:optional_stopping_near-martingale_continuous}.
\begin{corollary}  \label{thm:optional_stopping_near-martingale_special}
    Let \( N \) be a non-negative near-martingale with right-continuous sample paths and \( œÑ \) a bounded stopping time. Then \( N(œÑ) \) is integrable, and \( \E\br{N(œÑ)} = \E\br{N(0)} \) almost surely.
\end{corollary}
