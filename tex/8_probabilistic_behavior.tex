% !TeX root = ../dissertation.tex

\section{Rare events and asymptotic analysis}
\footnotetextonly{\Cref{sec:LDP_constant,sec:LDP_random} previously appeared in the following open-access article: \fullcite{KuoShresthaSinhaSundar2022}.}

In mathematics, particularly in analysis, we are frequently concerned with asymptotic behavior of mathematical objects. Elementary probability theory gives us some simple tools to know the asymptotic behavior of means of random variables. First, the law of large numbers says that if we repeat the same experiment a large number of times, we should expect the empirical mean of the result to be close to the theoretical mean.

To formalize this, assume we have a sequence of independent and identically distributed (i.i.d.) integrable random variables \( \br{X_n}_{n = 1}^‚àû \) with such that \( \E\br{X_1} = m \). Let \( S_n = ‚àë_{i = 1}^n X_i \) be the sum and \( \overline{X}_n = \frac{S_n}{n} \) be the empirical mean of \( n \) such random variables.
\begin{theorem}  \index{law of large numbers}
    \begin{align*}
        \overline{X}_n ‚Üí m \text{ as } n ‚Üí ‚àû  \quad  \text{almost surely or in \( \Pr \).}
    \end{align*}
    This is called the \emph{strong law of large numbers} if the convergence is almost surely. If the convergence is in probability, then the theorem is called the \emph{weak law of large numbers}.
\end{theorem}
Since almost sure convergence implies convergence in probability, the strong law implies the weak law. Even though it is called a \textquote{law} for historical reasons, it is a theorem of probability theory. Using notation from asymptotic analysis, we can write this as \( \overline{X}_n = m + o(1) \).

The law of large numbers do not give us any knowledge of how far down the sequence we have to go in order for our empirical means to come \textquote{close} to the theoretical mean. The central limit theorem helps in this regard.

\begin{theorem}[Lindeberg‚ÄìL√©vy]  \index{central limit theorem!Lindeberg‚ÄìL√©vy}
    Assume the setting above along with the condition that \( \V\br{X_1} = œÉ^2 < ‚àû \). Let \( Z ‚àº N(0, 1) \) be a standard normal variable. Then
    \begin{equation*}
        \sqrt{n} \br{\overline{X}_n - m} ‚Üí œÉ Z  \quad  \text{in distribution.}
    \end{equation*}
    Alternatively, in terms of the empirical sum \( S_n \), we can write this as
    \begin{equation*}
        \frac{S_n - n m}{\sqrt{n}} ‚Üí œÉ Z  \quad  \text{in distribution.}
    \end{equation*}
\end{theorem}

Therefore, the central limit theorem gives us one more level of detail. Asymptotically, it says that
\begin{equation*}
    \overline{X}_n ‚âÉ m + \frac{1}{\sqrt{n}} œÉ Z + o\br{\frac{1}{\sqrt{n}}} .
\end{equation*}
The tradeoff here is that we now have to contend ourselves with the weaker sense of convergence is in distribution.

Can we do better? Let us look at a specific example. Suppose that now all our random variables are i.i.d. standard normal, that is \( X_1 ‚àº N(0, 1) \). Then the moment generating function of \( X_1 \) is given by \( M(Œ∏) = \E\br{e^{Œ∏ X_1}} = e^{\frac12 Œ∏^2} \). We write the moment generating function of \( S_n \) as
\begin{equation*}
    M_{S_n}(Œ∏)
    =  \E\br{e^{Œ∏ S_n}}
    =  \E\br{e^{Œ∏ ‚àë_{i = 1}^n X_i}}
    =  \E\br{‚àè_{i = 1}^n e^{Œ∏ X_i}}
    =  ‚àè_{i = 1}^n \E\br{e^{Œ∏ X_i}} ,
\end{equation*}
where we used the independence assumption in the last step. Using the identical distribution assumption, we get
\begin{equation*}
    M_{S_n}(Œ∏)
    =  \br{\E\br{e^{Œ∏ X_1}}}^n
    =  \br{e^{\frac12 Œ∏^2}}^n
    =  e^{\frac12 Œ∏^2 n}
    =  e^{o(n)} .
\end{equation*}
On the other hand, using law of large numbers, we get \( S_n = n \overline{X}_n = o(n) \), and so
\begin{equation*}
    M_{S_n}(Œ∏)
    =  \E\br{e^{Œ∏ S_n}}
    =  \E\br{e^{o(n)}} ,
\end{equation*}
which does not equal \( e^{o(n)} \) that we obtained using the moment generating function approach.

Why does the moment generating function give us better results than the law of large numbers? For one, the moment generating function actually takes into account the distribution of the random variables and does not use any approximation. However, there is another simple explanation for this. When we compute the expectations of random variable that can take very large values with very small probabilities, we cannot simply ignore the contributions of such values. This is because the product \( p q \), where \( p \) is large and \( q \) is small depends on the magnitude of \( p \) and \( q \), and can be quite large.

These kinds of problems are the mainstay of the insurance industry. Actuaries have to compute the expectation of net payout given that probabilities of accidents are quite small. Consider the following real-world problem. Let the i.i.d. random variables \( X_n \) denote the value of claims received by an insurance company on the \( n \)th month. The steady income for the company per month is the premium \( x \). The company wants to use a planning period of \( n \) months to set the value of \( x \) so that they make a profit on average with a certain degree of certainty. Essentially, the goal is to determine \( x \) such that \( \Pr\br{\overline{X}_n ‚â• x} < œµ \), where \( œµ \) is an acceptable error probability. Therefore, it is hardly surprising that the theory of large deviations was started by actuarial mathematicians, prime among them being the Swedish mathematician Harald Cram√©r. However, it was Varadhan\cite{Varadhan1966} who formally defined large deviations and unified the various results into a coherent theory, for which he was awarded the Abel Prize in 2007.

To get an idea of what Cram√©r showed, we use Markov's inequality\index{Markov's inequality} to obtain exponential tail bounds of \( \overline{X}_n \). Suppose \( X_1 \) has a finite moment generating function \( M \). For an arbitrary \( Œ∏ > 0 \), using the i.i.d. nature of \( \br{X_n} \), we get
\begin{align*}
    \Pr\bc{\overline{X}_n ‚â• x}
    & =  \Pr\bc{e^{Œ∏ n \overline{X}_n} ‚â• e^{Œ∏ n x}}  \\
    & ‚â§  e^{-Œ∏ n x} \E\br{e^{Œ∏ n \overline{X}_n}}  \\
    & =  e^{-Œ∏ n x} M_{\overline{X}_n}(Œ∏ n)  \\
    & =  \br{e^{-Œ∏ x}}^n M(Œ∏)^n  \\
    & =  e^{-n \br{Œ∏ x - \log M(Œ∏)}} .
\end{align*}
Since \( Œ∏ > 0 \) is arbitrary, we have
\begin{equation*}
    \Pr\bc{\overline{X}_n ‚â• x}
    ‚â§  \inf_Œ∏ e^{-n \br{Œ∏ x - \log M(Œ∏)}}
    =  e^{-n \sup_Œ∏ \br{Œ∏ x - \log M(Œ∏)}} .
\end{equation*}
Letting \( Œõ^*(x) := \sup_{Œ∏ > 0} \bc{Œ∏ x - \log M(Œ∏)} \), moving all terms dependent on \( n \) to the left, and taking \( \varlimsup \), we get
\[ \varlimsup_{n ‚Üí ‚àû} \frac1n \log \Pr\bc{\overline{X}_n ‚â• x} ‚â§ Œõ^*(x) . \]
Now, instead of the set \( [x, ‚àû) \), if we consider an arbitrary closed set \( F \), we can expect
\[ \varlimsup_{n ‚Üí ‚àû} \frac1n \log \Pr\bc{\overline{X}_n ‚àà F} ‚â§ \inf_{x ‚àà F} Œõ^*(x) . \]
This is called a \emph{large deviation upper bound}.

In fact, for this case, we can also obtain a \emph{large deviation lower bound}. This means that for any arbitrary open set \( G \), we can expect
\[ \varliminf_{n ‚Üí ‚àû} \frac1n \log \Pr\bc{\overline{X}_n ‚àà G} ‚â• \inf_{x ‚àà G} Œõ^*(x) . \]

This is the statement of the famous Cram√©r's theorem\index{Cram√©r's theorem}.
\begin{theorem}[\cite{Cram√©r1938}]
    The following hold.
    \begin{enumerate}
        \item  (upper bound)  For every closed set \( F \),
            \[ \varlimsup_{n ‚Üí ‚àû} \frac1n \log \Pr\bc{\overline{X}_n ‚àà F}  ‚â§  - \inf_{x ‚àà F} Œõ^*(x) . \]
        \item  (lower bound)  For every open set \( G \),
            \[ \varliminf_{n ‚Üí ‚àû} \frac1n \log \Pr\bc{\overline{X}_n ‚àà G}  ‚â•  - \inf_{x ‚àà G} Œõ^*(x) . \]
    \end{enumerate}
\end{theorem}

Putting the two bounds together, we say that \( \br{\overline{X}_n} \) follows a \emph{large deviation principle} with \emph{rate function} \( Œõ^* \), and we informally write
\[ \Pr\bc{\overline{X}_n ‚àà \dif x} ‚âç e^{-n Œõ^*(x)} . \]

In essence, the theory of large deviation allow us to find probabilities of rare events that decay exponentially.

Even though the theory of large deviations originated in the works of Scandinavian actuaries, it has become one of the central topics in probability theory, having found numerous applications in the seemingly disparate fields of dynamical systems, statistical mechanics, information theory, and fluid mechanics, among others.



\section{Large deviation principles}
We now formally define large deviation principles in a general setting. Recall that a Polish space is any space that is homeomorphic to a complete metric space having a countable dense subset.
\begin{definition}
    Let \( (ùí≥, d) \) be a Polish space and \( \br{Œº^œµ}_{œµ > 0} \) a sequence of Borel probability measures on \( ùí≥ \). Suppose \( I: ùí≥ ‚Üí [0, ‚àû] \) is a lower semicontinuous functional. Then the sequence \( \br{Œº^œµ}_{œµ > 0} \) is said to satisfy a \emph{large deviation principle}\index{large deviation principle} (LDP) on \( ùí≥ \) with \emph{rate function}\index{rate function} \( I \) if and only if for each Borel measurable \( E ‚äÜ ùí≥ \),
    \begin{equation*}
        - \inf_{x ‚àà E^‚àò} I(x) ‚â§ œµ \varliminf_{œµ ‚Üí 0} \log Œº^œµ(E) ‚â§ œµ \varlimsup_{œµ ‚Üí 0} \log Œº^œµ(E) ‚â§ - \inf_{x ‚àà \overline{E}} I(x) ,
    \end{equation*}
    where \( E^‚àò \) and \( \overline{E} \) are the interior and closure of \( E \), respectively.

    Equivalently, the sequence \( \br{Œº^œµ}_{œµ > 0} \) is said to satisfy a large deviation principle with rate function \( I \) if and only if
    \begin{enumerate}
        \item  (upper bound)\index{large deviation principle!upper bound}  for every closed set \( F ‚äÜ ùí≥ \),
            \[ \varlimsup_{œµ ‚Üí 0} œµ \log Œº^œµ(F)  ‚â§  - \inf_{x ‚àà F} I(x) , \]
        \item  (lower bound)\index{large deviation principle!lower bound}  and for every open set \( G ‚äÜ ùí≥ \),
            \[ \varliminf_{œµ ‚Üí 0} œµ \log Œº^œµ(G)  ‚â•  - \inf_{x ‚àà G} I(x) . \]
    \end{enumerate}
\end{definition}

Recall that we used the second version to write Cram√©r's theorem in the previous section.

The next result states how LDPs are transferred under continuous transformations.
\begin{theorem}[contraction/continuity principle {\cite[theorem 4.2.1]{DemboZeitouni1998}}]  \label{thm:LDP_continuity_principle}  \index{continuity principle}
    Let \( ùí≥ \) and \( ùí¥ \) be Hausdorff spaces and \( f: ùí≥ ‚Üí ùí¥ \) a continuous function. Suppose the sequence of probability measures \( \br{Œº^œµ}_{œµ > 0} \) on \( ùí≥ \) satisfy a large deviation principle with rate function \( I: ùí≥ ‚Üí [0, ‚àû] \). For each \( y ‚àà ùí¥ \), define \( J(y) = \inf \bc{(I ‚àò \inv{f})(y)} \). Then the sequence of pushforward probability measures \( \br{Œº^œµ ‚àò \inv{f}}_{œµ > 0} \) on \( ùí¥ \) satisfy a large deviation principle with rate function \( J: ùí¥ ‚Üí [0, ‚àû] \).
\end{theorem}

Are there situations where a large deviation principle is preserved? To answer this, we define exponential equivalence of measures.
\begin{definition}[{\cite[definition 4.2.10]{DemboZeitouni1998}}]
    Let \( (ùí≥, d) \) be a Polish space with two families of measures \( \br{Œº^œµ}_{œµ > 0} \) and \( \br{ŒΩ^œµ}_{œµ > 0} \) on it. Suppose there exists probability spaces \( \br{Œ©, Œ£_œµ, \Pr_œµ} \) and two families of \( ùí≥ \)-valued random variables \( \br{X^œµ}_{œµ > 0} \) and \( \br{Y^œµ}_{œµ > 0} \) with joint laws \( \br{\Pr_œµ}_{œµ > 0} \) and marginals \( \br{Œº^œµ}_{œµ > 0} \) and \( \br{ŒΩ^œµ}_{œµ > 0} \), respectively. Moreover, for all \( Œ¥ > 0 \), the set \( \bc{œâ \given (X^œµ, Y^œµ) ‚àà E_Œ¥} \) is \( Œ£_œµ \)-measurable, and \( \varlimsup_{œµ ‚Üí 0} œµ \log \Pr_œµ\br{E_Œ¥} = -‚àû \), where \( E_Œ¥ = \bc{(x, y) \given d(x, y) > Œ¥} ‚äÜ ùí≥^2 \). Then the families \( \br{Œº^œµ}_{œµ > 0} \) and \( \br{ŒΩ^œµ}_{œµ > 0} \) (and correspondingly \( \br{X^œµ}_{œµ > 0} \) and \( \br{Y^œµ}_{œµ > 0} \)) are called \emph{exponentially equivalent}\index{exponential equivalence}.
\end{definition}

Exponentially equivalent families of measures induce the same large deviation principle. This is the content of the following theorem.
\begin{theorem}[{\cite[theorem 4.2.13]{DemboZeitouni1998}}]  \label{thm:LDP_exponential_equivalence}
    Suppose the families \( \br{Œº^œµ}_{œµ > 0} \) and \( \br{ŒΩ^œµ}_{œµ > 0} \) of measures on \( ùí≥ \) are exponentially equivalent. Then \( \br{Œº^œµ}_{œµ > 0} \) satisfies a large deviation principle with rate function \( I \) if and only if \( \br{ŒΩ^œµ}_{œµ > 0} \) satisfies a large deviation principle with the same rate function \( I \).
\end{theorem}




\section{Sample path large deviations}

Just as in the previous chapter, we fix \( t ‚àà [0, 1] \). We state everything in one-dimension, even though all of the results of the section can be replaced by their higher-dimensional equivalents.

Recall that \( \br{ùíû_0, \norm{‚ãÖ}_‚àû} \) is the space of real-valued continuous functions on \( [0, 1] \) and \( ‚Ñã^1 \) the Cameron‚ÄìMartin space\index{Cameron‚ÄìMartin space}. Let the translation of the set \( ùíû_0 \) by \( Œ∫ ‚àà ‚Ñù \) be denoted using \( ùíû_Œ∫ \). Similarly, \( ‚Ñã^1_Œ∫ \) denotes the linear translation of \( ‚Ñã^1 \) by \( Œ∫ ‚àà ‚Ñù \).

Consider the family of process \( \br{\sqrt{œµ} W}_{œµ > 0} \), where a Wiener process \( W \) is scaled down by a parameter \( \sqrt{œµ} \). Since for every \( t \), the random variable \( W_t ‚àº N(0, t) \), and so \( \sqrt{œµ} W_t ‚àº N(0, œµ t) \). Therefore, as \( œµ ‚Üí 0 \), the sequence \( \sqrt{œµ} W_t ‚Üí 0 \) in probability (also almost surely). Can we determine the rate of this convergence? In other words, can we estimate the probability that a scaled-down sample path of a Brownian motion will stray far from the mean path? This is answered by Schilder's theorem\index{Schilder's theorem}.
\begin{theorem}[\cite{Schilder1966}]  \label{thm:Schilder}
    For every \( œµ \), let \( Œº^œµ \) be the law of \( \sqrt{œµ} W \) on \( \br{ùíû_0, \norm{‚ãÖ}_‚àû} \). Then \( \br{Œº^œµ}_{œµ > 0} \) satisfies a large deviation principle with rate function
    \begin{equation*}
        I(œâ) =
        \begin{cases}
            \frac12 ‚à´_0^1 \abs{œâ'(t)}^2 \dif t  &  \text{if } œâ ‚àà ‚Ñã^1 , \\
            ‚àû  &  \text{otherwise} .
        \end{cases}
    \end{equation*}
\end{theorem}

\begin{example}
    Define the \emph{reverse Wiener process}\index{reverse Wiener process} as \( V^t = W_1 - W_t \). For every \( œµ \), let \( ŒΩ^œµ \) be the law of \( \sqrt{œµ} V \) on the space of continuous functions \( f: [0, 1] ‚Üí ‚Ñù \) such that \( f(1) = 0 \) embedded with the supremum norm. Then \( \br{ŒΩ^œµ}_{œµ > 0} \) satisfies a large deviation principle with rate function
    \begin{equation*}
        J(œï) =
        \begin{cases}
            \frac12 ‚à´_0^1 \abs{f(t)}^2 \dif t  &  \text{if } œï(t) = ‚à´_0^{1-t} f(s) \dif s \text{ for some } f ‚àà L^2[0, 1] , \\
            ‚àû  &  \text{otherwise} .
        \end{cases}
    \end{equation*}
\end{example}

\begin{proof}
    Define \( Z_t =  W_1 - W_{1-t} \). Then we have the following properties:
    \begin{enumerate}
        \item  \( Z_0 = W_1 - W_1 = 0 \) almost surely.
        \item  For \( 0 ‚â§ u ‚â§ v ‚â§ s ‚â§ t ‚â§ 1 \), the increment \( Z_t - Z_s = W_{1-s} - W_{1-t} \) is independent of \( Z_v - Z_u = W_{1-u} - W_{1-v} \) due to the independence of increments of \( W \) (see \cref{fig:reverse_Wiener_increments}).
        \item  \( Z_t - Z_s = W_{1-s} - W_{1-t} ‚àº N(0, t-s) \) for any \( 0 ‚â§ s ‚â§ t ‚â§ 1 \).
        \item  The paths of \( Z \) are continuous almost surely since they are just a sum of continuous functions.
    \end{enumerate}
    From \cref{def:Wiener_process}, we see that \( Z \) is a Brownian motion. Therefore, \cref{thm:Schilder} applies for the family of processes \( \br{\sqrt{œµ} Z}_{œµ > 0} \).

    \begin{figure}
        \centering
        \begin{tikzpicture}
            % Main timeline
            \draw [-, very thick, color=gray] (-2,0) -- (10,0) node[below] {\(  \)};
            \foreach \x/\xtext in {-2/0, 0/1-t, 3/1-s, 5/1-v, 8/1-u, 10/1}
                \draw [ultra thick] (\x cm,1pt) -- (\x cm,-1pt) node[anchor=north] {$\xtext$};

            % # Adapted
            % f_{i-1}
            \draw [very thick, color=SeaGreen] (0,1) -- (3,1);
            \draw[color=SeaGreen] (1.5,1.3) node {\( Z_t - Z_s \)};
            \draw [fill=SeaGreen] (0,1) circle (1.5pt);
            \draw [fill=SeaGreen] (3,1) circle (1.5pt);

            % # Instantly independent

            % \phi_j
            \draw [very thick, color=MidnightBlue] (5,1) -- (8,1);
            \draw[color=MidnightBlue] (6.5,1.3) node {\( Z_v - Z_u \)};
            \draw [fill=MidnightBlue] (5,1) circle (1.5pt);
            \draw [fill=MidnightBlue] (8,1) circle (1.5pt);

            % Setup and bounding box
            % \clip(-2,-1) rectangle (9,3);
            % \draw (current bounding box.north east) rectangle (current bounding box.south west);
        \end{tikzpicture}
        \caption{The disjoint increments of \( Z \).}
        \label{fig:reverse_Wiener_increments}
    \end{figure}

    Consider the function \( Œ∏ : ùíû ‚Üí ùíû : œï(t) ‚Ü¶ œï(1-t) \), where \( ùíû \) is the space of continuous functions. Note that \( Œ∏ \) is an continuous involution on \( ùíû \). Moreover,
    \[ Œ∏(\sqrt{œµ} Z_t)  = Œ∏(\sqrt{œµ} (W_1 - W_{1-t})) = \sqrt{œµ} (W_1 - W_t) = \sqrt{œµ} V^t ‚àº ŒΩ^œµ . \]
    Using the continuity principle (\cref{thm:LDP_continuity_principle}) along with the rate function \( I \) from \cref{thm:Schilder}, \( \br{ŒΩ^œµ}_{œµ > 0} \) follows a large deviation principle with the rate function given by
    \begin{align*}
        J(œï)
        & =  I ‚àò Œ∏^{-1} (œï(‚ãÖ))  =  I(œï(1 - ‚ãÖ)) \\
        & =  \begin{cases}
            \frac12 ‚à´_0^1 \abs{f(t)}^2 \dif t  &  \text{if } œï(1 - t) = ‚à´_0^t f(s) \dif s \text{ for some } f ‚àà L^2[0, 1]  \\
            ‚àû  &  \text{otherwise}
        \end{cases}  \\
        & =  \begin{cases}
            \frac12 ‚à´_0^1 \abs{f(t)}^2 \dif t  &  \text{if } œï(t) = ‚à´_0^{1-t} f(s) \dif s \text{ for some } f ‚àà L^2[0, 1]  \\
            ‚àû  &  \text{otherwise} .
        \end{cases}
    \end{align*}
\end{proof}


The extension of Schilder's theorem to It√¥ diffusions is the content of the \emph{Freidlin‚ÄìWentzell theory}\index{Freidlin‚ÄìWentzell theory}. We start with a simple situation where we perturb an ordinary differential equation with a diffusion that goes to zero as \( œµ ‚Üí 0 \). Let \( X^œµ \) denote the unique solution of the stochastic differential equation
\begin{equation*}
    \left\{
    \begin{aligned}
        \dif X^œµ_t  & =  b(X^œµ_t) \dif t + \sqrt{œµ} \dif W_t , \\
             X^œµ_0  & =  0 ,
    \end{aligned}
    \right.
\end{equation*}
where \( b: ‚Ñù ‚Üí ‚Ñù \) is a uniformly Lipschitz continuous function. Let \( \br{ŒΩ^œµ}_{œµ > 0} \) be the sequence of probability measures induced by \( \br{X^œµ}_{œµ > 0} \) on \( \br{ùíû_0, \norm{‚ãÖ}_‚àû} \).
\begin{theorem}[{\cite[theorem 5.6.3]{DemboZeitouni1998}}]  \label{thm:LDP_Freidlin‚ÄìWentzell_simple}
    \( \br{ŒΩ^œµ}_{œµ > 0} \) satisfies a large deviation principle with rate function
    \begin{equation*}
        I(f) =
        \begin{cases}
            \frac12 ‚à´_0^1 \abs{f'(t) - b(f(t))}^2 \dif t  &  \text{if } f ‚àà ‚Ñã^1 , \\
            ‚àû  &  \text{otherwise} .
        \end{cases}
    \end{equation*}
\end{theorem}
The idea of the proof again rests on the continuity principle given in \cref{thm:LDP_continuity_principle}. Let us elaborate further. Suppose \( F: ùíû_0 ‚Üí ùíû_0 \) be the deterministic map determined by \( f = F(g) \), where \( f \) is the unique continuous solution of
\[ f(t) = ‚à´_0^t b(f(s)) \dif s + g(t) . \]
Then \( ŒΩ^œµ = Œº^œµ ‚àò \inv{F} \), where \( Œº^œµ \) is the measure induced by \( \sqrt{œµ} W \) on \( \br{ùíû_0, \norm{‚ãÖ}_‚àû} \). Now we can apply the continuity principle to arrive at the required large deviation principle result.

Finally, we look at the general case. Suppose \( Œ∫ ‚àà ‚Ñù \), the functions \( b: ‚Ñù ‚Üí ‚Ñù \) and \( œÉ: ‚Ñù ‚Üí ‚Ñù \) are bounded uniformly Lipschitz continuous functions, and \( œÉ \) is uniformly bounded away from \( 0 \). Let \( X^œµ \) be the diffusion process that is the unique solution of the stochastic differential equation\index{stochastic differential equation}
\begin{equation*}
    \left\{
    \begin{aligned}
        \dif Y^œµ_t  & =  b(Y^œµ_t) \dif t + \sqrt{œµ} œÉ(Y^œµ_t) \dif W_t , \\
             Y^œµ_0  & =  Œ∫ .
    \end{aligned}
    \right.
\end{equation*}
\begin{theorem}[Freidlin‚ÄìWentzell {\cite[theorem 5.6.7]{DemboZeitouni1998}}]
    The sequence of probability measures induced by \( \br{Y^œµ}_{œµ > 0} \) on \( \br{ùíû_0, \norm{‚ãÖ}_‚àû} \) satisfies a large deviation principle with rate function
    \begin{equation*}
        I_x(f) =
        \begin{cases}
            \frac12 ‚à´_0^1 \abs{\frac{1}{œÉ(f(t))} \br{f'(t) - b(f(t))}}^2 \dif t  &  \text{if } f ‚àà ‚Ñã^1_x , \\
            ‚àû  &  \text{otherwise} .
        \end{cases}
    \end{equation*}
\end{theorem}



\section{LSDEs with anticipating coefficients and constant initial condition}  \label{sec:LDP_constant}

In what follows, we develop a Freidlin‚ÄìWentzell type result for linear stochastic differential equations with anticipating coefficients. In particular, we look at a class of linear stochastic differential equations of the type \cref{eqn:SDE_drift} that we analyzed in \cref{chp:solving_ALSDEs}. We start off with the case of constant initial conditions.

Suppose \( œÉ \) and \( Œ≥ \) are deterministic functions of bounded variation on \( [0, 1] \). Moreover, suppose \( f ‚àà C^2(‚Ñù) \) is Lipschitz continuous along with \( f, f', f'' ‚àà L^1(‚Ñù) \). For a fixed \( Œ∫ ‚àà ‚Ñù \), consider the family of linear stochastic differential equations with parameter \( œµ > 0 \) given by
\begin{equation}  \label{eqn:SDE_drift_LDP_constant}
    \left\{
    \begin{aligned}
        \dif Z^œµ_Œ∫(t)  & =  f\br{\sqrt{œµ} ‚à´_0^1 Œ≥(s) \dif W_s} Z^œµ_Œ∫(t) \dif t + \sqrt{œµ} œÉ(t) ~ Z^œµ_Œ∫(t) \dif W_t  \\
             Z^œµ_Œ∫(0)  & =  Œ∫ ,
    \end{aligned}
    \right.
\end{equation}
Using the results from \cref{chp:solving_ALSDEs}, the unique solutions to \cref{eqn:SDE_drift_LDP_constant} are given by
\begin{align}  \label{eqn:SDE_drift_solution_Ayed‚ÄìKuo_LDP_constant}
    Z^œµ_Œ∫(t) =  Œ∫ \exp
    &  \left[ \sqrt{œµ} ‚à´_0^t œÉ(s) \dif W_s - \frac{œµ}{2} ‚à´_0^t œÉ(s)^2 \dif s \right.  \nonumber \\
    &  \left. + ‚à´_0^t f\br{ \sqrt{œµ} ‚à´_0^1 Œ≥(u) \dif W_u - œµ ‚à´_s^t Œ≥(u) ~ œÉ(u) \dif u } \dif s \right] .
\end{align}

Our approach will be similar to how the Freidlin‚ÄìWentzell results in \cref{thm:LDP_Freidlin‚ÄìWentzell_simple} are derived from Schilder's theorem (\cref{thm:Schilder}) using the continuity principle (\cref{thm:LDP_continuity_principle}). In order to use the continuity principle, we need the following lemma.

\begin{lemma}  \label{thm:Œ∏_continuity}
    The function \( Œ∏: ùíû_0 ‚Üí ùíû_Œ∫ \) defined by
    \begin{align*}
        Œ∏(x)  =  Œ∫ \exp
        &  \left[ ‚à´_0^t œÉ(s) \dif x(s) - \frac{œµ}{2} ‚à´_0^t œÉ(s)^2 \dif s \right.  \\
        &  \left. + ‚à´_0^t f\br{ ‚à´_0^1 Œ≥(u) \dif x(u) - œµ ‚à´_s^t Œ≥(u) ~ œÉ(u) \dif u } \dif s \right]
    \end{align*}
    is continuous in the topology induced by the canonical supremum norm.
\end{lemma}

\begin{proof}
    We can write
    \[ Œ∏(x)  =  Œ∫ \exp\bs{ œï(x) - \frac{œµ}{2} ‚à´_0^t œÉ_s^2 \dif s + œà(x) } , \]
    where \( œï, œà: ùíû_0 ‚Üí ùíû_0 \) is given by
    \begin{align*}
        œï(x)  & =  ‚à´_0^t œÉ(s) \dif x(s)  =  œÉ(t) x(t) - ‚à´_0^t x(s) \dif œÉ(s) , \text{ and} \\
        œà(x)  & =  ‚à´_0^t f\br{ ‚à´_0^1 Œ≥(u) \dif x(u) - œµ ‚à´_s^t Œ≥(u) ~ œÉ(u) \dif u } \dif s .
    \end{align*}
    Using integration by parts,
    \begin{align*}
        œï(x)  & =  œÉ(t) x(t) - ‚à´_0^t x(s) \dif œÉ(s) , \text{ and} \\
        œà(x)  & =  ‚à´_0^t f\br{ Œ≥(1) x(1) - ‚à´_0^1 x(s) \dif Œ≥(s) - œµ ‚à´_s^t Œ≥(u) ~ œÉ(u) \dif u } \dif s .
    \end{align*}
    Since multiplication by \( Œ∫ \exp\br{- \frac{œµ}{2} ‚à´_0^t œÉ_s^2 \dif s} \) and \( \exp \) are continuous transformations, continuity of \( Œ∏ \) is guaranteed if we prove continuity of \( œï \) and \( œà \). This is what we show below. For \( œï \), we have
    \begin{align*}
        \norm{œï(x) - œï(y)}_‚àû
        & =  \norm{\br{œÉ(t) x(t) - ‚à´_0^t x(s) \dif œÉ(s)} - \br{œÉ(t) y(t) - ‚à´_0^t y(s) \dif œÉ(s)}}_‚àû  \\
        & ‚â§  \norm{œÉ(t) \br{x(t) - y(t)}}_‚àû + \norm{‚à´_0^t (x(s) - y(s)) \dif œÉ(s)}_‚àû  \\
        & ‚â§  \norm{œÉ}_‚àû \norm{x - y}_‚àû  +  \abs{œÉ(t) - œÉ(0)} \norm{x - y}_‚àû  \\
        & ‚â§  3 \norm{œÉ}_‚àû \norm{x - y}_‚àû ,
    \end{align*}
    so \( œï \) is continuous.

    For \( œà \), if \( L_f \) is the Lipschitz constant for \( f \), we get
    \begin{align*}
        \norm{œà(x) - œà(y)}_‚àû
        ‚â§ &  \left\lVert ‚à´_0^t L_f \left[ \br{ Œ≥(1) x(1) - ‚à´_0^1 x(s) \dif Œ≥(s) - \cancel{œµ ‚à´_s^t Œ≥(u) ~ œÉ_u \dif u} } \right. \right.  \\
        & \qquad  - \left. \left. \br{ Œ≥(1) y(1) - ‚à´_0^1 y(s) \dif Œ≥(s) - \cancel{œµ ‚à´_s^t Œ≥(u) ~ œÉ_u \dif u} } \right] \dif s \right\rVert_‚àû  \\
        ‚â§ &  L_f \norm{ ‚à´_0^t \br{Œ≥(1) \br{x(1) - y(1)} - ‚à´_0^1 \br{x(s) - y(s)} \dif Œ≥(s)} \dif s }_‚àû  \\
        ‚â§ &  L_f \br{\norm{Œ≥}_‚àû \norm{x - y}_‚àû + \abs{Œ≥(1) - Œ≥(0)} \norm{x - y}}_‚àû  \\
        = &  3 L_f \norm{Œ≥}_‚àû \norm{x - y}_‚àû ,
    \end{align*}
    which proves the continuity of \( œà \).
\end{proof}


The following result now follows directly from the continuity of \( Œ∏ \) (\cref{thm:Œ∏_continuity}), the continuity principle (\cref{thm:LDP_continuity_principle}), and Schilder's theorem (\cref{thm:Schilder}).
\begin{theorem}  \label{thm:SDE_drift_LDP_constant}
    The laws of the solutions \( Z^œµ_Œ∫ \) given by \cref{eqn:SDE_drift_solution_Ayed‚ÄìKuo_LDP_constant} of the family of stochastic differential equations given by \cref{eqn:SDE_drift_LDP_constant} follow a large deviation principle on \( \br{ùíû_Œ∫, \norm{‚ãÖ}_‚àû} \) with the rate function
    \begin{equation}  \label{eqn:SDE_drift_LDP_rate}
        J(y) = \inf \bc{I ‚àò \inv{Œ∏} (y)} ,
    \end{equation}
    where \( Œ∏ \) is as defined in \cref{thm:Œ∏_continuity}, and \( I \) is the Schilder's rate function given in \cref{thm:Schilder}.
\end{theorem}



\section{LSDEs with anticipating coefficients and random initial condition}  \label{sec:LDP_random}

Is it not necessary for the family of linear stochastic differential equations \cref{eqn:SDE_drift_LDP_constant} to start at a constant point \( Œ∫ ‚àà ‚Ñù \) in order for it to have a large deviation principle. In this section, we generalize \cref{thm:SDE_drift_LDP_constant} and show that we can derive a similar result under a stronger version of exponential equivalence\index{exponential equivalence} and more restrictive conditions on the functions \( f \), \( œÉ \), and \( Œ≥ \).

Suppose \( œÉ \) and \( Œ≥ \) are deterministic functions of bounded variation on \( [0, 1] \). Moreover, suppose \( f ‚àà C^2(‚Ñù) \) is Lipschitz continuous along with \( f, f', f'' ‚àà L^1(‚Ñù) \). Consider the family of linear stochastic differential equations with parameter \( œµ > 0 \) given by
\begin{equation}  \label{eqn:SDE_drift_LDP_random}
    \left\{
    \begin{aligned}
        \dif Z^œµ_Œæ(t)  & =  f\br{\sqrt{œµ} ‚à´_0^1 Œ≥(s) \dif W_s} Z^œµ_Œæ(t) \dif t + \sqrt{œµ} œÉ_t ~ Z^œµ_Œæ(t) \dif W_t  \\
             Z^œµ_Œæ(0)  & =  Œæ^œµ ,
    \end{aligned}
    \right.
\end{equation}
where \( Œæ^œµ \)s are random variables independent of the Wiener process \( W \). Just as before, the unique solutions to \cref{eqn:SDE_drift_LDP_random} are given by
\begin{align}  \label{eqn:SDE_drift_solution_Ayed‚ÄìKuo_LDP_random}
    Z^œµ_Œæ(t) =  Œæ^œµ \exp
    &  \left[ \sqrt{œµ} ‚à´_0^t œÉ(s) \dif W_s - \frac{œµ}{2} ‚à´_0^t œÉ(s)^2 \dif s \right.  \nonumber \\
    &  \left. + ‚à´_0^t f\br{ \sqrt{œµ} ‚à´_0^1 Œ≥(u) \dif W_u - œµ ‚à´_s^t Œ≥(u) ~ œÉ(u) \dif u } \dif s \right]
\end{align}

We now state a more general large deviation principle.
\begin{theorem}
    Let \( Œ∫ ‚àà ‚Ñù \) and consider the family of random variables \( Œæ^œµ \) such that the following hold
    \begin{equation}  \label{eqn:SDE_drift_LDP_exponential_equivalence}
        \lim_{œµ ‚Üí 0} œµ \log \E\bs{\br{Œæ^œµ - Œ∫}^2} = -‚àû .
    \end{equation}
    Moreover, assume that the functions \( f, f', œÉ, Œ≥ \) are all bounded. Then the laws of the solutions \( Z^œµ_Œæ \) given by \cref{eqn:SDE_drift_solution_Ayed‚ÄìKuo_LDP_random} of the family of stochastic differential equations given by \cref{eqn:SDE_drift_LDP_random} follow a large deviation principle on \( \br{ùíû_Œ∫, \norm{‚ãÖ}_‚àû} \) with the rate function given by \cref{eqn:SDE_drift_LDP_rate}, where \( Œ∏ \) is as defined in \cref{thm:Œ∏_continuity}, and \( I \) is the Schilder's rate function given in \cref{thm:Schilder}.
\end{theorem}
\begin{proof}
    Let \( V^œµ = Z^œµ_Œæ - Z^œµ_Œ∫ \). Then \( V^œµ \) satisfies the stochastic differential equation
    \begin{equation}  \label{eqn:SDE_drift_LDP_difference}
        \left\{
        \begin{aligned}
            \dif V^œµ(t)  & =  f\br{\sqrt{œµ} ‚à´_0^1 Œ≥(s) \dif W_s} V^œµ(t) \dif t + \sqrt{œµ} œÉ_t V^œµ(t) \dif W_t  \\
                 V^œµ(0)  & =  Œæ^œµ - Œ∫ ,
        \end{aligned}
        \right.
    \end{equation}
    whose solution is given by
    \begin{align*}
        V^œµ(t)  =  \br{Œæ^œµ - Œ∫} \exp
        &  \left[ \sqrt{œµ} ‚à´_0^t œÉ_s \dif W_s - \frac{œµ}{2} ‚à´_0^t œÉ_s^2 \dif s \right.  \\
        &  \left. + ‚à´_0^t f\br{ \sqrt{œµ} ‚à´_0^1 Œ≥(u) \dif W_u - œµ ‚à´_s^t Œ≥(u) ~ œÉ_u \dif u } \dif s \right] .
    \end{align*}

    Let \( œï(z) = \abs{z}^2 \) and let \( U^œµ = œï(V^œµ) \). From \cref{thm:SDE_drift_solution_squared}, \( U^œµ \) satisfies the integral equation
    \begin{align*}
        U^œµ(t)  =
        &  \br{Œæ^œµ - Œ∫}^2  +  2 \sqrt{œµ} ‚à´_0^t œÉ_s ~ U^œµ(s) \dif W_s  \\
        & +  œµ ‚à´_0^t œÉ_s^2 ~ U^œµ(s) \dif s  +  f\br{‚à´_0^1 \sqrt{œµ} ~ Œ≥(s) \dif W_s} ‚à´_0^t U^œµ(s) \dif s  \\
        & +  2 œµ ‚à´_0^t Œ≥(s) ~ œÉ_s ~ U^œµ(s) ‚à´_0^s f'\br{‚à´_0^1 \sqrt{œµ} ~ Œ≥(v) \dif W_v - œµ ‚à´_u^s Œ≥(v) ~ œÉ_v \dif v} \dif u \dif s .
    \end{align*}

    Fix \( Œ¥ > 0 \) and let \( œÑ = \inf\bc{t ‚àà [0, 1] : \abs{V^œµ(t)} ‚â• Œ¥} \). Taking expectation of the stopped process \( U^œµ(t ‚àß œÑ) \), we get
    \begin{align*}
        &  \E\br{U^œµ(t ‚àß œÑ)}  \\
        & =  \E\bs{\br{Œæ^œµ - Œ∫}^2}  +  2 \sqrt{œµ} \E\bs{‚à´_0^{t ‚àß œÑ} œÉ_s ~ U^œµ(s ‚àß œÑ) \dif W_s}  \\
        & \quad +  œµ \E\bs{‚à´_0^{t ‚àß œÑ} œÉ_s^2 ~ U^œµ(s ‚àß œÑ) \dif s}  +  \E\bs{f\br{‚à´_0^1 \sqrt{œµ} ~ Œ≥(s) \dif W_s} ‚à´_0^{t ‚àß œÑ} U^œµ(s ‚àß œÑ) \dif s}  \\
        & \quad +  2 œµ \E\bs{‚à´_0^{t ‚àß œÑ} Œ≥(s) ~ œÉ_s ~ U^œµ(s ‚àß œÑ) ‚à´_0^s f'\br{‚à´_0^1 \sqrt{œµ} ~ Œ≥(v) \dif W_v - œµ ‚à´_u^s Œ≥(v) ~ œÉ_v \dif v} \dif u \dif s} .
    \end{align*}
    The second integral on the right-hand side is a near-martingales by \cref{thm:Ayed‚ÄìKuo_integral_near-martingale}. Suppose \( f, f', œÉ, Œ≥ \) are all bounded by some \( M > 1 \). Using non-negativity of \( U^œµ \) and the near-martingale optional stopping theorem (\cref{thm:optional_stopping_near-martingale_special}), we get
    \begin{align*}
        \E\br{U^œµ(t ‚àß œÑ)}
        ‚â§ &  \E\bs{\br{Œæ^œµ - Œ∫}^2}  +  0  \\
          & +  œµ M^2 \E\bs{‚à´_0^{t ‚àß œÑ} U^œµ(s ‚àß œÑ) \dif s}  +  M \E\bs{‚à´_0^{t ‚àß œÑ} U^œµ(s ‚àß œÑ) \dif s}  \\
          & +  2 œµ M^3 \E\bs{‚à´_0^{t ‚àß œÑ} U^œµ(s ‚àß œÑ) \dif s}  \\
        ‚â§ &  \E\bs{\br{Œæ^œµ - Œ∫}^2} + \br{M + 2 œµ M^3} \E\bs{‚à´_0^{t ‚àß œÑ} U^œµ(s ‚àß œÑ) \dif s} .
    \end{align*}
    By Gronwall's inequality, we get
    \[ \E\br{U^œµ(œÑ)}  =  \E\br{U^œµ(1 ‚àß œÑ)}  ‚â§  \E\bs{\br{Œæ^œµ - Œ∫}^2} e^{M + 2 œµ M^3} . \]

    Since \( œï(z) \) is a monotonically increasing nonnegative function in \( \abs{z} \), we use Markov's inequality to get
    \begin{equation*}
        \Pr\bc{\abs{V^œµ(œÑ)} ‚â• Œ¥}
        = \Pr\bc{œï(V^œµ(œÑ)) ‚â• œï(Œ¥)}
        ‚â§  \frac{\E\br{œï(V^œµ(œÑ))}}{œï(Œ¥)}
        =  \frac{\E\br{U^œµ(œÑ)}}{Œ¥^2}
        ‚â§  \frac{\E\bs{\br{Œæ^œµ - Œ∫}^2}}{Œ¥^2} e^{M + 2 œµ M^3} .
    \end{equation*}
    Taking \( \log \) and multiplying by \( œµ \), we get
    \[ œµ \log \Pr\bc{\abs{V^œµ(œÑ)} ‚â• Œ¥}  ‚â§  œµ \log \E\bs{\br{Œæ^œµ - Œ∫}^2} - 2 œµ \log Œ¥ + œµ (M + 2 œµ M^3) . \]
    Finally, taking limit of \( œµ ‚Üí 0 \) and using \cref{eqn:SDE_drift_LDP_exponential_equivalence},
    \[ \lim_{œµ ‚Üí 0} œµ \log \Pr\bc{\abs{V^œµ(œÑ)} ‚â• Œ¥}  =  -‚àû . \]
    This result allows us to say that \( Z^œµ_Œæ \) and \( Z^œµ_Œ∫ \) are exponentially equivalent. Since exponentially equivalent families have the same large deviation principle due to \cref{thm:LDP_exponential_equivalence}, \( Z^œµ_Œæ \) follows a large deviation principle with the same rate function given by \cref{eqn:SDE_drift_LDP_rate}.
\end{proof}
